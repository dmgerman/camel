begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/*  * Licensed to the Apache Software Foundation (ASF) under one or more  * contributor license agreements.  See the NOTICE file distributed with  * this work for additional information regarding copyright ownership.  * The ASF licenses this file to You under the Apache License, Version 2.0  * (the "License"); you may not use this file except in compliance with  * the License.  You may obtain a copy of the License at  *  *      http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
DECL|package|org.apache.camel.builder.endpoint.dsl
package|package
name|org
operator|.
name|apache
operator|.
name|camel
operator|.
name|builder
operator|.
name|endpoint
operator|.
name|dsl
package|;
end_package

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Map
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|ScheduledExecutorService
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|TimeUnit
import|;
end_import

begin_import
import|import
name|javax
operator|.
name|annotation
operator|.
name|Generated
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|camel
operator|.
name|ExchangePattern
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|camel
operator|.
name|LoggingLevel
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|camel
operator|.
name|builder
operator|.
name|EndpointConsumerBuilder
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|camel
operator|.
name|builder
operator|.
name|EndpointProducerBuilder
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|camel
operator|.
name|builder
operator|.
name|endpoint
operator|.
name|AbstractEndpointBuilder
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|camel
operator|.
name|spi
operator|.
name|ExceptionHandler
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|camel
operator|.
name|spi
operator|.
name|PollingConsumerPollStrategy
import|;
end_import

begin_comment
comment|/**  * For reading/writing from/to an HDFS filesystem using Hadoop 2.x.  *   * Generated by camel-package-maven-plugin - do not edit this file!  */
end_comment

begin_interface
annotation|@
name|Generated
argument_list|(
literal|"org.apache.camel.maven.packaging.EndpointDslMojo"
argument_list|)
DECL|interface|HdfsEndpointBuilderFactory
specifier|public
interface|interface
name|HdfsEndpointBuilderFactory
block|{
comment|/**      * Builder for endpoint consumers for the HDFS component.      */
DECL|interface|HdfsEndpointConsumerBuilder
specifier|public
interface|interface
name|HdfsEndpointConsumerBuilder
extends|extends
name|EndpointConsumerBuilder
block|{
DECL|method|advanced ()
specifier|default
name|AdvancedHdfsEndpointConsumerBuilder
name|advanced
parameter_list|()
block|{
return|return
operator|(
name|AdvancedHdfsEndpointConsumerBuilder
operator|)
name|this
return|;
block|}
comment|/**          * Whether to connect to the HDFS file system on starting the          * producer/consumer. If false then the connection is created on-demand.          * Notice that HDFS may take up till 15 minutes to establish a          * connection, as it has hardcoded 45 x 20 sec redelivery. By setting          * this option to false allows your application to startup, and not          * block for up till 15 minutes.          *           * The option is a:<code>boolean</code> type.          *           * Group: common          */
DECL|method|connectOnStartup ( boolean connectOnStartup)
specifier|default
name|HdfsEndpointConsumerBuilder
name|connectOnStartup
parameter_list|(
name|boolean
name|connectOnStartup
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"connectOnStartup"
argument_list|,
name|connectOnStartup
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * Whether to connect to the HDFS file system on starting the          * producer/consumer. If false then the connection is created on-demand.          * Notice that HDFS may take up till 15 minutes to establish a          * connection, as it has hardcoded 45 x 20 sec redelivery. By setting          * this option to false allows your application to startup, and not          * block for up till 15 minutes.          *           * The option will be converted to a<code>boolean</code> type.          *           * Group: common          */
DECL|method|connectOnStartup ( String connectOnStartup)
specifier|default
name|HdfsEndpointConsumerBuilder
name|connectOnStartup
parameter_list|(
name|String
name|connectOnStartup
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"connectOnStartup"
argument_list|,
name|connectOnStartup
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * Set to LOCAL to not use HDFS but local java.io.File instead.          *           * The option is a:          *<code>org.apache.camel.component.hdfs.HdfsFileSystemType</code> type.          *           * Group: common          */
DECL|method|fileSystemType ( HdfsFileSystemType fileSystemType)
specifier|default
name|HdfsEndpointConsumerBuilder
name|fileSystemType
parameter_list|(
name|HdfsFileSystemType
name|fileSystemType
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"fileSystemType"
argument_list|,
name|fileSystemType
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * Set to LOCAL to not use HDFS but local java.io.File instead.          *           * The option will be converted to a          *<code>org.apache.camel.component.hdfs.HdfsFileSystemType</code> type.          *           * Group: common          */
DECL|method|fileSystemType (String fileSystemType)
specifier|default
name|HdfsEndpointConsumerBuilder
name|fileSystemType
parameter_list|(
name|String
name|fileSystemType
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"fileSystemType"
argument_list|,
name|fileSystemType
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * The file type to use. For more details see Hadoop HDFS documentation          * about the various files types.          *           * The option is a:          *<code>org.apache.camel.component.hdfs.HdfsFileType</code> type.          *           * Group: common          */
DECL|method|fileType (HdfsFileType fileType)
specifier|default
name|HdfsEndpointConsumerBuilder
name|fileType
parameter_list|(
name|HdfsFileType
name|fileType
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"fileType"
argument_list|,
name|fileType
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * The file type to use. For more details see Hadoop HDFS documentation          * about the various files types.          *           * The option will be converted to a          *<code>org.apache.camel.component.hdfs.HdfsFileType</code> type.          *           * Group: common          */
DECL|method|fileType (String fileType)
specifier|default
name|HdfsEndpointConsumerBuilder
name|fileType
parameter_list|(
name|String
name|fileType
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"fileType"
argument_list|,
name|fileType
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * The type for the key in case of sequence or map files.          *           * The option is a:          *<code>org.apache.camel.component.hdfs.WritableType</code> type.          *           * Group: common          */
DECL|method|keyType (WritableType keyType)
specifier|default
name|HdfsEndpointConsumerBuilder
name|keyType
parameter_list|(
name|WritableType
name|keyType
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"keyType"
argument_list|,
name|keyType
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * The type for the key in case of sequence or map files.          *           * The option will be converted to a          *<code>org.apache.camel.component.hdfs.WritableType</code> type.          *           * Group: common          */
DECL|method|keyType (String keyType)
specifier|default
name|HdfsEndpointConsumerBuilder
name|keyType
parameter_list|(
name|String
name|keyType
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"keyType"
argument_list|,
name|keyType
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * A comma separated list of named nodes (e.g.          * srv11.example.com:8020,srv12.example.com:8020).          *           * The option is a:<code>java.lang.String</code> type.          *           * Group: common          */
DECL|method|namedNodes (String namedNodes)
specifier|default
name|HdfsEndpointConsumerBuilder
name|namedNodes
parameter_list|(
name|String
name|namedNodes
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"namedNodes"
argument_list|,
name|namedNodes
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * The file owner must match this owner for the consumer to pickup the          * file. Otherwise the file is skipped.          *           * The option is a:<code>java.lang.String</code> type.          *           * Group: common          */
DECL|method|owner (String owner)
specifier|default
name|HdfsEndpointConsumerBuilder
name|owner
parameter_list|(
name|String
name|owner
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"owner"
argument_list|,
name|owner
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * The type for the key in case of sequence or map files.          *           * The option is a:          *<code>org.apache.camel.component.hdfs.WritableType</code> type.          *           * Group: common          */
DECL|method|valueType (WritableType valueType)
specifier|default
name|HdfsEndpointConsumerBuilder
name|valueType
parameter_list|(
name|WritableType
name|valueType
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"valueType"
argument_list|,
name|valueType
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * The type for the key in case of sequence or map files.          *           * The option will be converted to a          *<code>org.apache.camel.component.hdfs.WritableType</code> type.          *           * Group: common          */
DECL|method|valueType (String valueType)
specifier|default
name|HdfsEndpointConsumerBuilder
name|valueType
parameter_list|(
name|String
name|valueType
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"valueType"
argument_list|,
name|valueType
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * Allows for bridging the consumer to the Camel routing Error Handler,          * which mean any exceptions occurred while the consumer is trying to          * pickup incoming messages, or the likes, will now be processed as a          * message and handled by the routing Error Handler. By default the          * consumer will use the org.apache.camel.spi.ExceptionHandler to deal          * with exceptions, that will be logged at WARN or ERROR level and          * ignored.          *           * The option is a:<code>boolean</code> type.          *           * Group: consumer          */
DECL|method|bridgeErrorHandler ( boolean bridgeErrorHandler)
specifier|default
name|HdfsEndpointConsumerBuilder
name|bridgeErrorHandler
parameter_list|(
name|boolean
name|bridgeErrorHandler
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"bridgeErrorHandler"
argument_list|,
name|bridgeErrorHandler
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * Allows for bridging the consumer to the Camel routing Error Handler,          * which mean any exceptions occurred while the consumer is trying to          * pickup incoming messages, or the likes, will now be processed as a          * message and handled by the routing Error Handler. By default the          * consumer will use the org.apache.camel.spi.ExceptionHandler to deal          * with exceptions, that will be logged at WARN or ERROR level and          * ignored.          *           * The option will be converted to a<code>boolean</code> type.          *           * Group: consumer          */
DECL|method|bridgeErrorHandler ( String bridgeErrorHandler)
specifier|default
name|HdfsEndpointConsumerBuilder
name|bridgeErrorHandler
parameter_list|(
name|String
name|bridgeErrorHandler
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"bridgeErrorHandler"
argument_list|,
name|bridgeErrorHandler
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * The pattern used for scanning the directory.          *           * The option is a:<code>java.lang.String</code> type.          *           * Group: consumer          */
DECL|method|pattern (String pattern)
specifier|default
name|HdfsEndpointConsumerBuilder
name|pattern
parameter_list|(
name|String
name|pattern
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"pattern"
argument_list|,
name|pattern
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * If the polling consumer did not poll any files, you can enable this          * option to send an empty message (no body) instead.          *           * The option is a:<code>boolean</code> type.          *           * Group: consumer          */
DECL|method|sendEmptyMessageWhenIdle ( boolean sendEmptyMessageWhenIdle)
specifier|default
name|HdfsEndpointConsumerBuilder
name|sendEmptyMessageWhenIdle
parameter_list|(
name|boolean
name|sendEmptyMessageWhenIdle
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"sendEmptyMessageWhenIdle"
argument_list|,
name|sendEmptyMessageWhenIdle
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * If the polling consumer did not poll any files, you can enable this          * option to send an empty message (no body) instead.          *           * The option will be converted to a<code>boolean</code> type.          *           * Group: consumer          */
DECL|method|sendEmptyMessageWhenIdle ( String sendEmptyMessageWhenIdle)
specifier|default
name|HdfsEndpointConsumerBuilder
name|sendEmptyMessageWhenIdle
parameter_list|(
name|String
name|sendEmptyMessageWhenIdle
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"sendEmptyMessageWhenIdle"
argument_list|,
name|sendEmptyMessageWhenIdle
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * Sets the download method to use when not using a local working          * directory. If set to true, the remote files are streamed to the route          * as they are read. When set to false, the remote files are loaded into          * memory before being sent into the route.          *           * The option is a:<code>boolean</code> type.          *           * Group: consumer          */
DECL|method|streamDownload ( boolean streamDownload)
specifier|default
name|HdfsEndpointConsumerBuilder
name|streamDownload
parameter_list|(
name|boolean
name|streamDownload
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"streamDownload"
argument_list|,
name|streamDownload
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * Sets the download method to use when not using a local working          * directory. If set to true, the remote files are streamed to the route          * as they are read. When set to false, the remote files are loaded into          * memory before being sent into the route.          *           * The option will be converted to a<code>boolean</code> type.          *           * Group: consumer          */
DECL|method|streamDownload (String streamDownload)
specifier|default
name|HdfsEndpointConsumerBuilder
name|streamDownload
parameter_list|(
name|String
name|streamDownload
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"streamDownload"
argument_list|,
name|streamDownload
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * The number of subsequent error polls (failed due some error) that          * should happen before the backoffMultipler should kick-in.          *           * The option is a:<code>int</code> type.          *           * Group: scheduler          */
DECL|method|backoffErrorThreshold ( int backoffErrorThreshold)
specifier|default
name|HdfsEndpointConsumerBuilder
name|backoffErrorThreshold
parameter_list|(
name|int
name|backoffErrorThreshold
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"backoffErrorThreshold"
argument_list|,
name|backoffErrorThreshold
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * The number of subsequent error polls (failed due some error) that          * should happen before the backoffMultipler should kick-in.          *           * The option will be converted to a<code>int</code> type.          *           * Group: scheduler          */
DECL|method|backoffErrorThreshold ( String backoffErrorThreshold)
specifier|default
name|HdfsEndpointConsumerBuilder
name|backoffErrorThreshold
parameter_list|(
name|String
name|backoffErrorThreshold
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"backoffErrorThreshold"
argument_list|,
name|backoffErrorThreshold
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * The number of subsequent idle polls that should happen before the          * backoffMultipler should kick-in.          *           * The option is a:<code>int</code> type.          *           * Group: scheduler          */
DECL|method|backoffIdleThreshold ( int backoffIdleThreshold)
specifier|default
name|HdfsEndpointConsumerBuilder
name|backoffIdleThreshold
parameter_list|(
name|int
name|backoffIdleThreshold
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"backoffIdleThreshold"
argument_list|,
name|backoffIdleThreshold
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * The number of subsequent idle polls that should happen before the          * backoffMultipler should kick-in.          *           * The option will be converted to a<code>int</code> type.          *           * Group: scheduler          */
DECL|method|backoffIdleThreshold ( String backoffIdleThreshold)
specifier|default
name|HdfsEndpointConsumerBuilder
name|backoffIdleThreshold
parameter_list|(
name|String
name|backoffIdleThreshold
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"backoffIdleThreshold"
argument_list|,
name|backoffIdleThreshold
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * To let the scheduled polling consumer backoff if there has been a          * number of subsequent idles/errors in a row. The multiplier is then          * the number of polls that will be skipped before the next actual          * attempt is happening again. When this option is in use then          * backoffIdleThreshold and/or backoffErrorThreshold must also be          * configured.          *           * The option is a:<code>int</code> type.          *           * Group: scheduler          */
DECL|method|backoffMultiplier ( int backoffMultiplier)
specifier|default
name|HdfsEndpointConsumerBuilder
name|backoffMultiplier
parameter_list|(
name|int
name|backoffMultiplier
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"backoffMultiplier"
argument_list|,
name|backoffMultiplier
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * To let the scheduled polling consumer backoff if there has been a          * number of subsequent idles/errors in a row. The multiplier is then          * the number of polls that will be skipped before the next actual          * attempt is happening again. When this option is in use then          * backoffIdleThreshold and/or backoffErrorThreshold must also be          * configured.          *           * The option will be converted to a<code>int</code> type.          *           * Group: scheduler          */
DECL|method|backoffMultiplier ( String backoffMultiplier)
specifier|default
name|HdfsEndpointConsumerBuilder
name|backoffMultiplier
parameter_list|(
name|String
name|backoffMultiplier
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"backoffMultiplier"
argument_list|,
name|backoffMultiplier
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * Milliseconds before the next poll. You can also specify time values          * using units, such as 60s (60 seconds), 5m30s (5 minutes and 30          * seconds), and 1h (1 hour).          *           * The option is a:<code>long</code> type.          *           * Group: scheduler          */
DECL|method|delay (long delay)
specifier|default
name|HdfsEndpointConsumerBuilder
name|delay
parameter_list|(
name|long
name|delay
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"delay"
argument_list|,
name|delay
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * Milliseconds before the next poll. You can also specify time values          * using units, such as 60s (60 seconds), 5m30s (5 minutes and 30          * seconds), and 1h (1 hour).          *           * The option will be converted to a<code>long</code> type.          *           * Group: scheduler          */
DECL|method|delay (String delay)
specifier|default
name|HdfsEndpointConsumerBuilder
name|delay
parameter_list|(
name|String
name|delay
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"delay"
argument_list|,
name|delay
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * If greedy is enabled, then the ScheduledPollConsumer will run          * immediately again, if the previous run polled 1 or more messages.          *           * The option is a:<code>boolean</code> type.          *           * Group: scheduler          */
DECL|method|greedy (boolean greedy)
specifier|default
name|HdfsEndpointConsumerBuilder
name|greedy
parameter_list|(
name|boolean
name|greedy
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"greedy"
argument_list|,
name|greedy
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * If greedy is enabled, then the ScheduledPollConsumer will run          * immediately again, if the previous run polled 1 or more messages.          *           * The option will be converted to a<code>boolean</code> type.          *           * Group: scheduler          */
DECL|method|greedy (String greedy)
specifier|default
name|HdfsEndpointConsumerBuilder
name|greedy
parameter_list|(
name|String
name|greedy
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"greedy"
argument_list|,
name|greedy
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * Milliseconds before the first poll starts. You can also specify time          * values using units, such as 60s (60 seconds), 5m30s (5 minutes and 30          * seconds), and 1h (1 hour).          *           * The option is a:<code>long</code> type.          *           * Group: scheduler          */
DECL|method|initialDelay (long initialDelay)
specifier|default
name|HdfsEndpointConsumerBuilder
name|initialDelay
parameter_list|(
name|long
name|initialDelay
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"initialDelay"
argument_list|,
name|initialDelay
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * Milliseconds before the first poll starts. You can also specify time          * values using units, such as 60s (60 seconds), 5m30s (5 minutes and 30          * seconds), and 1h (1 hour).          *           * The option will be converted to a<code>long</code> type.          *           * Group: scheduler          */
DECL|method|initialDelay (String initialDelay)
specifier|default
name|HdfsEndpointConsumerBuilder
name|initialDelay
parameter_list|(
name|String
name|initialDelay
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"initialDelay"
argument_list|,
name|initialDelay
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * Specifies a maximum limit of number of fires. So if you set it to 1,          * the scheduler will only fire once. If you set it to 5, it will only          * fire five times. A value of zero or negative means fire forever.          *           * The option is a:<code>long</code> type.          *           * Group: scheduler          */
DECL|method|repeatCount (long repeatCount)
specifier|default
name|HdfsEndpointConsumerBuilder
name|repeatCount
parameter_list|(
name|long
name|repeatCount
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"repeatCount"
argument_list|,
name|repeatCount
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * Specifies a maximum limit of number of fires. So if you set it to 1,          * the scheduler will only fire once. If you set it to 5, it will only          * fire five times. A value of zero or negative means fire forever.          *           * The option will be converted to a<code>long</code> type.          *           * Group: scheduler          */
DECL|method|repeatCount (String repeatCount)
specifier|default
name|HdfsEndpointConsumerBuilder
name|repeatCount
parameter_list|(
name|String
name|repeatCount
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"repeatCount"
argument_list|,
name|repeatCount
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * The consumer logs a start/complete log line when it polls. This          * option allows you to configure the logging level for that.          *           * The option is a:<code>org.apache.camel.LoggingLevel</code> type.          *           * Group: scheduler          */
DECL|method|runLoggingLevel ( LoggingLevel runLoggingLevel)
specifier|default
name|HdfsEndpointConsumerBuilder
name|runLoggingLevel
parameter_list|(
name|LoggingLevel
name|runLoggingLevel
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"runLoggingLevel"
argument_list|,
name|runLoggingLevel
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * The consumer logs a start/complete log line when it polls. This          * option allows you to configure the logging level for that.          *           * The option will be converted to a          *<code>org.apache.camel.LoggingLevel</code> type.          *           * Group: scheduler          */
DECL|method|runLoggingLevel ( String runLoggingLevel)
specifier|default
name|HdfsEndpointConsumerBuilder
name|runLoggingLevel
parameter_list|(
name|String
name|runLoggingLevel
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"runLoggingLevel"
argument_list|,
name|runLoggingLevel
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * Allows for configuring a custom/shared thread pool to use for the          * consumer. By default each consumer has its own single threaded thread          * pool.          *           * The option is a:          *<code>java.util.concurrent.ScheduledExecutorService</code> type.          *           * Group: scheduler          */
DECL|method|scheduledExecutorService ( ScheduledExecutorService scheduledExecutorService)
specifier|default
name|HdfsEndpointConsumerBuilder
name|scheduledExecutorService
parameter_list|(
name|ScheduledExecutorService
name|scheduledExecutorService
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"scheduledExecutorService"
argument_list|,
name|scheduledExecutorService
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * Allows for configuring a custom/shared thread pool to use for the          * consumer. By default each consumer has its own single threaded thread          * pool.          *           * The option will be converted to a          *<code>java.util.concurrent.ScheduledExecutorService</code> type.          *           * Group: scheduler          */
DECL|method|scheduledExecutorService ( String scheduledExecutorService)
specifier|default
name|HdfsEndpointConsumerBuilder
name|scheduledExecutorService
parameter_list|(
name|String
name|scheduledExecutorService
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"scheduledExecutorService"
argument_list|,
name|scheduledExecutorService
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * To use a cron scheduler from either camel-spring or camel-quartz          * component.          *           * The option is a:<code>java.lang.String</code> type.          *           * Group: scheduler          */
DECL|method|scheduler (String scheduler)
specifier|default
name|HdfsEndpointConsumerBuilder
name|scheduler
parameter_list|(
name|String
name|scheduler
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"scheduler"
argument_list|,
name|scheduler
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * To configure additional properties when using a custom scheduler or          * any of the Quartz, Spring based scheduler.          *           * The option is a:<code>java.util.Map&lt;java.lang.String,          * java.lang.Object&gt;</code> type.          *           * Group: scheduler          */
DECL|method|schedulerProperties ( Map<String, Object> schedulerProperties)
specifier|default
name|HdfsEndpointConsumerBuilder
name|schedulerProperties
parameter_list|(
name|Map
argument_list|<
name|String
argument_list|,
name|Object
argument_list|>
name|schedulerProperties
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"schedulerProperties"
argument_list|,
name|schedulerProperties
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * To configure additional properties when using a custom scheduler or          * any of the Quartz, Spring based scheduler.          *           * The option will be converted to a          *<code>java.util.Map&lt;java.lang.String, java.lang.Object&gt;</code>          * type.          *           * Group: scheduler          */
DECL|method|schedulerProperties ( String schedulerProperties)
specifier|default
name|HdfsEndpointConsumerBuilder
name|schedulerProperties
parameter_list|(
name|String
name|schedulerProperties
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"schedulerProperties"
argument_list|,
name|schedulerProperties
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * Whether the scheduler should be auto started.          *           * The option is a:<code>boolean</code> type.          *           * Group: scheduler          */
DECL|method|startScheduler ( boolean startScheduler)
specifier|default
name|HdfsEndpointConsumerBuilder
name|startScheduler
parameter_list|(
name|boolean
name|startScheduler
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"startScheduler"
argument_list|,
name|startScheduler
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * Whether the scheduler should be auto started.          *           * The option will be converted to a<code>boolean</code> type.          *           * Group: scheduler          */
DECL|method|startScheduler (String startScheduler)
specifier|default
name|HdfsEndpointConsumerBuilder
name|startScheduler
parameter_list|(
name|String
name|startScheduler
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"startScheduler"
argument_list|,
name|startScheduler
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * Time unit for initialDelay and delay options.          *           * The option is a:<code>java.util.concurrent.TimeUnit</code> type.          *           * Group: scheduler          */
DECL|method|timeUnit (TimeUnit timeUnit)
specifier|default
name|HdfsEndpointConsumerBuilder
name|timeUnit
parameter_list|(
name|TimeUnit
name|timeUnit
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"timeUnit"
argument_list|,
name|timeUnit
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * Time unit for initialDelay and delay options.          *           * The option will be converted to a          *<code>java.util.concurrent.TimeUnit</code> type.          *           * Group: scheduler          */
DECL|method|timeUnit (String timeUnit)
specifier|default
name|HdfsEndpointConsumerBuilder
name|timeUnit
parameter_list|(
name|String
name|timeUnit
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"timeUnit"
argument_list|,
name|timeUnit
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * Controls if fixed delay or fixed rate is used. See          * ScheduledExecutorService in JDK for details.          *           * The option is a:<code>boolean</code> type.          *           * Group: scheduler          */
DECL|method|useFixedDelay (boolean useFixedDelay)
specifier|default
name|HdfsEndpointConsumerBuilder
name|useFixedDelay
parameter_list|(
name|boolean
name|useFixedDelay
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"useFixedDelay"
argument_list|,
name|useFixedDelay
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * Controls if fixed delay or fixed rate is used. See          * ScheduledExecutorService in JDK for details.          *           * The option will be converted to a<code>boolean</code> type.          *           * Group: scheduler          */
DECL|method|useFixedDelay (String useFixedDelay)
specifier|default
name|HdfsEndpointConsumerBuilder
name|useFixedDelay
parameter_list|(
name|String
name|useFixedDelay
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"useFixedDelay"
argument_list|,
name|useFixedDelay
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * The location of the kerb5.conf file          * (https://web.mit.edu/kerberos/krb5-1.12/doc/admin/conf_files/krb5_conf.html).          *           * The option is a:<code>java.lang.String</code> type.          *           * Group: security          */
DECL|method|kerberosConfigFileLocation ( String kerberosConfigFileLocation)
specifier|default
name|HdfsEndpointConsumerBuilder
name|kerberosConfigFileLocation
parameter_list|(
name|String
name|kerberosConfigFileLocation
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"kerberosConfigFileLocation"
argument_list|,
name|kerberosConfigFileLocation
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * The location of the keytab file used to authenticate with the          * kerberos nodes (contains pairs of kerberos principals and encrypted          * keys (which are derived from the Kerberos password)).          *           * The option is a:<code>java.lang.String</code> type.          *           * Group: security          */
DECL|method|kerberosKeytabLocation ( String kerberosKeytabLocation)
specifier|default
name|HdfsEndpointConsumerBuilder
name|kerberosKeytabLocation
parameter_list|(
name|String
name|kerberosKeytabLocation
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"kerberosKeytabLocation"
argument_list|,
name|kerberosKeytabLocation
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * The username used to authenticate with the kerberos nodes.          *           * The option is a:<code>java.lang.String</code> type.          *           * Group: security          */
DECL|method|kerberosUsername ( String kerberosUsername)
specifier|default
name|HdfsEndpointConsumerBuilder
name|kerberosUsername
parameter_list|(
name|String
name|kerberosUsername
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"kerberosUsername"
argument_list|,
name|kerberosUsername
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
block|}
comment|/**      * Advanced builder for endpoint consumers for the HDFS component.      */
DECL|interface|AdvancedHdfsEndpointConsumerBuilder
specifier|public
interface|interface
name|AdvancedHdfsEndpointConsumerBuilder
extends|extends
name|EndpointConsumerBuilder
block|{
DECL|method|basic ()
specifier|default
name|HdfsEndpointConsumerBuilder
name|basic
parameter_list|()
block|{
return|return
operator|(
name|HdfsEndpointConsumerBuilder
operator|)
name|this
return|;
block|}
comment|/**          * To let the consumer use a custom ExceptionHandler. Notice if the          * option bridgeErrorHandler is enabled then this option is not in use.          * By default the consumer will deal with exceptions, that will be          * logged at WARN or ERROR level and ignored.          *           * The option is a:<code>org.apache.camel.spi.ExceptionHandler</code>          * type.          *           * Group: consumer (advanced)          */
DECL|method|exceptionHandler ( ExceptionHandler exceptionHandler)
specifier|default
name|AdvancedHdfsEndpointConsumerBuilder
name|exceptionHandler
parameter_list|(
name|ExceptionHandler
name|exceptionHandler
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"exceptionHandler"
argument_list|,
name|exceptionHandler
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * To let the consumer use a custom ExceptionHandler. Notice if the          * option bridgeErrorHandler is enabled then this option is not in use.          * By default the consumer will deal with exceptions, that will be          * logged at WARN or ERROR level and ignored.          *           * The option will be converted to a          *<code>org.apache.camel.spi.ExceptionHandler</code> type.          *           * Group: consumer (advanced)          */
DECL|method|exceptionHandler ( String exceptionHandler)
specifier|default
name|AdvancedHdfsEndpointConsumerBuilder
name|exceptionHandler
parameter_list|(
name|String
name|exceptionHandler
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"exceptionHandler"
argument_list|,
name|exceptionHandler
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * Sets the exchange pattern when the consumer creates an exchange.          *           * The option is a:<code>org.apache.camel.ExchangePattern</code> type.          *           * Group: consumer (advanced)          */
DECL|method|exchangePattern ( ExchangePattern exchangePattern)
specifier|default
name|AdvancedHdfsEndpointConsumerBuilder
name|exchangePattern
parameter_list|(
name|ExchangePattern
name|exchangePattern
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"exchangePattern"
argument_list|,
name|exchangePattern
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * Sets the exchange pattern when the consumer creates an exchange.          *           * The option will be converted to a          *<code>org.apache.camel.ExchangePattern</code> type.          *           * Group: consumer (advanced)          */
DECL|method|exchangePattern ( String exchangePattern)
specifier|default
name|AdvancedHdfsEndpointConsumerBuilder
name|exchangePattern
parameter_list|(
name|String
name|exchangePattern
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"exchangePattern"
argument_list|,
name|exchangePattern
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * A pluggable org.apache.camel.PollingConsumerPollingStrategy allowing          * you to provide your custom implementation to control error handling          * usually occurred during the poll operation before an Exchange have          * been created and being routed in Camel.          *           * The option is a:          *<code>org.apache.camel.spi.PollingConsumerPollStrategy</code> type.          *           * Group: consumer (advanced)          */
DECL|method|pollStrategy ( PollingConsumerPollStrategy pollStrategy)
specifier|default
name|AdvancedHdfsEndpointConsumerBuilder
name|pollStrategy
parameter_list|(
name|PollingConsumerPollStrategy
name|pollStrategy
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"pollStrategy"
argument_list|,
name|pollStrategy
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * A pluggable org.apache.camel.PollingConsumerPollingStrategy allowing          * you to provide your custom implementation to control error handling          * usually occurred during the poll operation before an Exchange have          * been created and being routed in Camel.          *           * The option will be converted to a          *<code>org.apache.camel.spi.PollingConsumerPollStrategy</code> type.          *           * Group: consumer (advanced)          */
DECL|method|pollStrategy ( String pollStrategy)
specifier|default
name|AdvancedHdfsEndpointConsumerBuilder
name|pollStrategy
parameter_list|(
name|String
name|pollStrategy
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"pollStrategy"
argument_list|,
name|pollStrategy
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * Whether the endpoint should use basic property binding (Camel 2.x) or          * the newer property binding with additional capabilities.          *           * The option is a:<code>boolean</code> type.          *           * Group: advanced          */
DECL|method|basicPropertyBinding ( boolean basicPropertyBinding)
specifier|default
name|AdvancedHdfsEndpointConsumerBuilder
name|basicPropertyBinding
parameter_list|(
name|boolean
name|basicPropertyBinding
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"basicPropertyBinding"
argument_list|,
name|basicPropertyBinding
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * Whether the endpoint should use basic property binding (Camel 2.x) or          * the newer property binding with additional capabilities.          *           * The option will be converted to a<code>boolean</code> type.          *           * Group: advanced          */
DECL|method|basicPropertyBinding ( String basicPropertyBinding)
specifier|default
name|AdvancedHdfsEndpointConsumerBuilder
name|basicPropertyBinding
parameter_list|(
name|String
name|basicPropertyBinding
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"basicPropertyBinding"
argument_list|,
name|basicPropertyBinding
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * The size of the HDFS blocks.          *           * The option is a:<code>long</code> type.          *           * Group: advanced          */
DECL|method|blockSize (long blockSize)
specifier|default
name|AdvancedHdfsEndpointConsumerBuilder
name|blockSize
parameter_list|(
name|long
name|blockSize
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"blockSize"
argument_list|,
name|blockSize
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * The size of the HDFS blocks.          *           * The option will be converted to a<code>long</code> type.          *           * Group: advanced          */
DECL|method|blockSize (String blockSize)
specifier|default
name|AdvancedHdfsEndpointConsumerBuilder
name|blockSize
parameter_list|(
name|String
name|blockSize
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"blockSize"
argument_list|,
name|blockSize
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * The buffer size used by HDFS.          *           * The option is a:<code>int</code> type.          *           * Group: advanced          */
DECL|method|bufferSize (int bufferSize)
specifier|default
name|AdvancedHdfsEndpointConsumerBuilder
name|bufferSize
parameter_list|(
name|int
name|bufferSize
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"bufferSize"
argument_list|,
name|bufferSize
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * The buffer size used by HDFS.          *           * The option will be converted to a<code>int</code> type.          *           * Group: advanced          */
DECL|method|bufferSize (String bufferSize)
specifier|default
name|AdvancedHdfsEndpointConsumerBuilder
name|bufferSize
parameter_list|(
name|String
name|bufferSize
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"bufferSize"
argument_list|,
name|bufferSize
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * How often (time in millis) in to run the idle checker background          * task. This option is only in use if the splitter strategy is IDLE.          *           * The option is a:<code>int</code> type.          *           * Group: advanced          */
DECL|method|checkIdleInterval ( int checkIdleInterval)
specifier|default
name|AdvancedHdfsEndpointConsumerBuilder
name|checkIdleInterval
parameter_list|(
name|int
name|checkIdleInterval
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"checkIdleInterval"
argument_list|,
name|checkIdleInterval
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * How often (time in millis) in to run the idle checker background          * task. This option is only in use if the splitter strategy is IDLE.          *           * The option will be converted to a<code>int</code> type.          *           * Group: advanced          */
DECL|method|checkIdleInterval ( String checkIdleInterval)
specifier|default
name|AdvancedHdfsEndpointConsumerBuilder
name|checkIdleInterval
parameter_list|(
name|String
name|checkIdleInterval
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"checkIdleInterval"
argument_list|,
name|checkIdleInterval
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * When reading a normal file, this is split into chunks producing a          * message per chunk.          *           * The option is a:<code>int</code> type.          *           * Group: advanced          */
DECL|method|chunkSize (int chunkSize)
specifier|default
name|AdvancedHdfsEndpointConsumerBuilder
name|chunkSize
parameter_list|(
name|int
name|chunkSize
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"chunkSize"
argument_list|,
name|chunkSize
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * When reading a normal file, this is split into chunks producing a          * message per chunk.          *           * The option will be converted to a<code>int</code> type.          *           * Group: advanced          */
DECL|method|chunkSize (String chunkSize)
specifier|default
name|AdvancedHdfsEndpointConsumerBuilder
name|chunkSize
parameter_list|(
name|String
name|chunkSize
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"chunkSize"
argument_list|,
name|chunkSize
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * The compression codec to use.          *           * The option is a:          *<code>org.apache.camel.component.hdfs.HdfsCompressionCodec</code>          * type.          *           * Group: advanced          */
DECL|method|compressionCodec ( HdfsCompressionCodec compressionCodec)
specifier|default
name|AdvancedHdfsEndpointConsumerBuilder
name|compressionCodec
parameter_list|(
name|HdfsCompressionCodec
name|compressionCodec
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"compressionCodec"
argument_list|,
name|compressionCodec
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * The compression codec to use.          *           * The option will be converted to a          *<code>org.apache.camel.component.hdfs.HdfsCompressionCodec</code>          * type.          *           * Group: advanced          */
DECL|method|compressionCodec ( String compressionCodec)
specifier|default
name|AdvancedHdfsEndpointConsumerBuilder
name|compressionCodec
parameter_list|(
name|String
name|compressionCodec
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"compressionCodec"
argument_list|,
name|compressionCodec
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * The compression type to use (is default not in use).          *           * The option is a:          *<code>org.apache.hadoop.io.SequenceFile$CompressionType</code> type.          *           * Group: advanced          */
DECL|method|compressionType ( CompressionType compressionType)
specifier|default
name|AdvancedHdfsEndpointConsumerBuilder
name|compressionType
parameter_list|(
name|CompressionType
name|compressionType
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"compressionType"
argument_list|,
name|compressionType
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * The compression type to use (is default not in use).          *           * The option will be converted to a          *<code>org.apache.hadoop.io.SequenceFile$CompressionType</code> type.          *           * Group: advanced          */
DECL|method|compressionType ( String compressionType)
specifier|default
name|AdvancedHdfsEndpointConsumerBuilder
name|compressionType
parameter_list|(
name|String
name|compressionType
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"compressionType"
argument_list|,
name|compressionType
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * When a file is opened for reading/writing the file is renamed with          * this suffix to avoid to read it during the writing phase.          *           * The option is a:<code>java.lang.String</code> type.          *           * Group: advanced          */
DECL|method|openedSuffix ( String openedSuffix)
specifier|default
name|AdvancedHdfsEndpointConsumerBuilder
name|openedSuffix
parameter_list|(
name|String
name|openedSuffix
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"openedSuffix"
argument_list|,
name|openedSuffix
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * Once the file has been read is renamed with this suffix to avoid to          * read it again.          *           * The option is a:<code>java.lang.String</code> type.          *           * Group: advanced          */
DECL|method|readSuffix (String readSuffix)
specifier|default
name|AdvancedHdfsEndpointConsumerBuilder
name|readSuffix
parameter_list|(
name|String
name|readSuffix
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"readSuffix"
argument_list|,
name|readSuffix
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * The HDFS replication factor.          *           * The option is a:<code>short</code> type.          *           * Group: advanced          */
DECL|method|replication ( short replication)
specifier|default
name|AdvancedHdfsEndpointConsumerBuilder
name|replication
parameter_list|(
name|short
name|replication
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"replication"
argument_list|,
name|replication
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * The HDFS replication factor.          *           * The option will be converted to a<code>short</code> type.          *           * Group: advanced          */
DECL|method|replication ( String replication)
specifier|default
name|AdvancedHdfsEndpointConsumerBuilder
name|replication
parameter_list|(
name|String
name|replication
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"replication"
argument_list|,
name|replication
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * In the current version of Hadoop opening a file in append mode is          * disabled since it's not very reliable. So, for the moment, it's only          * possible to create new files. The Camel HDFS endpoint tries to solve          * this problem in this way: If the split strategy option has been          * defined, the hdfs path will be used as a directory and files will be          * created using the configured UuidGenerator. Every time a splitting          * condition is met, a new file is created. The splitStrategy option is          * defined as a string with the following syntax:          * splitStrategy=ST:value,ST:value,... where ST can be: BYTES a new file          * is created, and the old is closed when the number of written bytes is          * more than value MESSAGES a new file is created, and the old is closed          * when the number of written messages is more than value IDLE a new          * file is created, and the old is closed when no writing happened in          * the last value milliseconds.          *           * The option is a:<code>java.lang.String</code> type.          *           * Group: advanced          */
DECL|method|splitStrategy ( String splitStrategy)
specifier|default
name|AdvancedHdfsEndpointConsumerBuilder
name|splitStrategy
parameter_list|(
name|String
name|splitStrategy
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"splitStrategy"
argument_list|,
name|splitStrategy
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * Sets whether synchronous processing should be strictly used, or Camel          * is allowed to use asynchronous processing (if supported).          *           * The option is a:<code>boolean</code> type.          *           * Group: advanced          */
DECL|method|synchronous ( boolean synchronous)
specifier|default
name|AdvancedHdfsEndpointConsumerBuilder
name|synchronous
parameter_list|(
name|boolean
name|synchronous
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"synchronous"
argument_list|,
name|synchronous
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * Sets whether synchronous processing should be strictly used, or Camel          * is allowed to use asynchronous processing (if supported).          *           * The option will be converted to a<code>boolean</code> type.          *           * Group: advanced          */
DECL|method|synchronous ( String synchronous)
specifier|default
name|AdvancedHdfsEndpointConsumerBuilder
name|synchronous
parameter_list|(
name|String
name|synchronous
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"synchronous"
argument_list|,
name|synchronous
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
block|}
comment|/**      * Builder for endpoint producers for the HDFS component.      */
DECL|interface|HdfsEndpointProducerBuilder
specifier|public
interface|interface
name|HdfsEndpointProducerBuilder
extends|extends
name|EndpointProducerBuilder
block|{
DECL|method|advanced ()
specifier|default
name|AdvancedHdfsEndpointProducerBuilder
name|advanced
parameter_list|()
block|{
return|return
operator|(
name|AdvancedHdfsEndpointProducerBuilder
operator|)
name|this
return|;
block|}
comment|/**          * Whether to connect to the HDFS file system on starting the          * producer/consumer. If false then the connection is created on-demand.          * Notice that HDFS may take up till 15 minutes to establish a          * connection, as it has hardcoded 45 x 20 sec redelivery. By setting          * this option to false allows your application to startup, and not          * block for up till 15 minutes.          *           * The option is a:<code>boolean</code> type.          *           * Group: common          */
DECL|method|connectOnStartup ( boolean connectOnStartup)
specifier|default
name|HdfsEndpointProducerBuilder
name|connectOnStartup
parameter_list|(
name|boolean
name|connectOnStartup
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"connectOnStartup"
argument_list|,
name|connectOnStartup
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * Whether to connect to the HDFS file system on starting the          * producer/consumer. If false then the connection is created on-demand.          * Notice that HDFS may take up till 15 minutes to establish a          * connection, as it has hardcoded 45 x 20 sec redelivery. By setting          * this option to false allows your application to startup, and not          * block for up till 15 minutes.          *           * The option will be converted to a<code>boolean</code> type.          *           * Group: common          */
DECL|method|connectOnStartup ( String connectOnStartup)
specifier|default
name|HdfsEndpointProducerBuilder
name|connectOnStartup
parameter_list|(
name|String
name|connectOnStartup
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"connectOnStartup"
argument_list|,
name|connectOnStartup
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * Set to LOCAL to not use HDFS but local java.io.File instead.          *           * The option is a:          *<code>org.apache.camel.component.hdfs.HdfsFileSystemType</code> type.          *           * Group: common          */
DECL|method|fileSystemType ( HdfsFileSystemType fileSystemType)
specifier|default
name|HdfsEndpointProducerBuilder
name|fileSystemType
parameter_list|(
name|HdfsFileSystemType
name|fileSystemType
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"fileSystemType"
argument_list|,
name|fileSystemType
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * Set to LOCAL to not use HDFS but local java.io.File instead.          *           * The option will be converted to a          *<code>org.apache.camel.component.hdfs.HdfsFileSystemType</code> type.          *           * Group: common          */
DECL|method|fileSystemType (String fileSystemType)
specifier|default
name|HdfsEndpointProducerBuilder
name|fileSystemType
parameter_list|(
name|String
name|fileSystemType
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"fileSystemType"
argument_list|,
name|fileSystemType
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * The file type to use. For more details see Hadoop HDFS documentation          * about the various files types.          *           * The option is a:          *<code>org.apache.camel.component.hdfs.HdfsFileType</code> type.          *           * Group: common          */
DECL|method|fileType (HdfsFileType fileType)
specifier|default
name|HdfsEndpointProducerBuilder
name|fileType
parameter_list|(
name|HdfsFileType
name|fileType
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"fileType"
argument_list|,
name|fileType
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * The file type to use. For more details see Hadoop HDFS documentation          * about the various files types.          *           * The option will be converted to a          *<code>org.apache.camel.component.hdfs.HdfsFileType</code> type.          *           * Group: common          */
DECL|method|fileType (String fileType)
specifier|default
name|HdfsEndpointProducerBuilder
name|fileType
parameter_list|(
name|String
name|fileType
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"fileType"
argument_list|,
name|fileType
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * The type for the key in case of sequence or map files.          *           * The option is a:          *<code>org.apache.camel.component.hdfs.WritableType</code> type.          *           * Group: common          */
DECL|method|keyType (WritableType keyType)
specifier|default
name|HdfsEndpointProducerBuilder
name|keyType
parameter_list|(
name|WritableType
name|keyType
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"keyType"
argument_list|,
name|keyType
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * The type for the key in case of sequence or map files.          *           * The option will be converted to a          *<code>org.apache.camel.component.hdfs.WritableType</code> type.          *           * Group: common          */
DECL|method|keyType (String keyType)
specifier|default
name|HdfsEndpointProducerBuilder
name|keyType
parameter_list|(
name|String
name|keyType
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"keyType"
argument_list|,
name|keyType
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * A comma separated list of named nodes (e.g.          * srv11.example.com:8020,srv12.example.com:8020).          *           * The option is a:<code>java.lang.String</code> type.          *           * Group: common          */
DECL|method|namedNodes (String namedNodes)
specifier|default
name|HdfsEndpointProducerBuilder
name|namedNodes
parameter_list|(
name|String
name|namedNodes
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"namedNodes"
argument_list|,
name|namedNodes
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * The file owner must match this owner for the consumer to pickup the          * file. Otherwise the file is skipped.          *           * The option is a:<code>java.lang.String</code> type.          *           * Group: common          */
DECL|method|owner (String owner)
specifier|default
name|HdfsEndpointProducerBuilder
name|owner
parameter_list|(
name|String
name|owner
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"owner"
argument_list|,
name|owner
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * The type for the key in case of sequence or map files.          *           * The option is a:          *<code>org.apache.camel.component.hdfs.WritableType</code> type.          *           * Group: common          */
DECL|method|valueType (WritableType valueType)
specifier|default
name|HdfsEndpointProducerBuilder
name|valueType
parameter_list|(
name|WritableType
name|valueType
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"valueType"
argument_list|,
name|valueType
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * The type for the key in case of sequence or map files.          *           * The option will be converted to a          *<code>org.apache.camel.component.hdfs.WritableType</code> type.          *           * Group: common          */
DECL|method|valueType (String valueType)
specifier|default
name|HdfsEndpointProducerBuilder
name|valueType
parameter_list|(
name|String
name|valueType
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"valueType"
argument_list|,
name|valueType
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * Append to existing file. Notice that not all HDFS file systems          * support the append option.          *           * The option is a:<code>boolean</code> type.          *           * Group: producer          */
DECL|method|append (boolean append)
specifier|default
name|HdfsEndpointProducerBuilder
name|append
parameter_list|(
name|boolean
name|append
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"append"
argument_list|,
name|append
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * Append to existing file. Notice that not all HDFS file systems          * support the append option.          *           * The option will be converted to a<code>boolean</code> type.          *           * Group: producer          */
DECL|method|append (String append)
specifier|default
name|HdfsEndpointProducerBuilder
name|append
parameter_list|(
name|String
name|append
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"append"
argument_list|,
name|append
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * Whether the producer should be started lazy (on the first message).          * By starting lazy you can use this to allow CamelContext and routes to          * startup in situations where a producer may otherwise fail during          * starting and cause the route to fail being started. By deferring this          * startup to be lazy then the startup failure can be handled during          * routing messages via Camel's routing error handlers. Beware that when          * the first message is processed then creating and starting the          * producer may take a little time and prolong the total processing time          * of the processing.          *           * The option is a:<code>boolean</code> type.          *           * Group: producer          */
DECL|method|lazyStartProducer ( boolean lazyStartProducer)
specifier|default
name|HdfsEndpointProducerBuilder
name|lazyStartProducer
parameter_list|(
name|boolean
name|lazyStartProducer
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"lazyStartProducer"
argument_list|,
name|lazyStartProducer
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * Whether the producer should be started lazy (on the first message).          * By starting lazy you can use this to allow CamelContext and routes to          * startup in situations where a producer may otherwise fail during          * starting and cause the route to fail being started. By deferring this          * startup to be lazy then the startup failure can be handled during          * routing messages via Camel's routing error handlers. Beware that when          * the first message is processed then creating and starting the          * producer may take a little time and prolong the total processing time          * of the processing.          *           * The option will be converted to a<code>boolean</code> type.          *           * Group: producer          */
DECL|method|lazyStartProducer ( String lazyStartProducer)
specifier|default
name|HdfsEndpointProducerBuilder
name|lazyStartProducer
parameter_list|(
name|String
name|lazyStartProducer
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"lazyStartProducer"
argument_list|,
name|lazyStartProducer
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * Whether to overwrite existing files with the same name.          *           * The option is a:<code>boolean</code> type.          *           * Group: producer          */
DECL|method|overwrite (boolean overwrite)
specifier|default
name|HdfsEndpointProducerBuilder
name|overwrite
parameter_list|(
name|boolean
name|overwrite
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"overwrite"
argument_list|,
name|overwrite
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * Whether to overwrite existing files with the same name.          *           * The option will be converted to a<code>boolean</code> type.          *           * Group: producer          */
DECL|method|overwrite (String overwrite)
specifier|default
name|HdfsEndpointProducerBuilder
name|overwrite
parameter_list|(
name|String
name|overwrite
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"overwrite"
argument_list|,
name|overwrite
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * The location of the kerb5.conf file          * (https://web.mit.edu/kerberos/krb5-1.12/doc/admin/conf_files/krb5_conf.html).          *           * The option is a:<code>java.lang.String</code> type.          *           * Group: security          */
DECL|method|kerberosConfigFileLocation ( String kerberosConfigFileLocation)
specifier|default
name|HdfsEndpointProducerBuilder
name|kerberosConfigFileLocation
parameter_list|(
name|String
name|kerberosConfigFileLocation
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"kerberosConfigFileLocation"
argument_list|,
name|kerberosConfigFileLocation
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * The location of the keytab file used to authenticate with the          * kerberos nodes (contains pairs of kerberos principals and encrypted          * keys (which are derived from the Kerberos password)).          *           * The option is a:<code>java.lang.String</code> type.          *           * Group: security          */
DECL|method|kerberosKeytabLocation ( String kerberosKeytabLocation)
specifier|default
name|HdfsEndpointProducerBuilder
name|kerberosKeytabLocation
parameter_list|(
name|String
name|kerberosKeytabLocation
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"kerberosKeytabLocation"
argument_list|,
name|kerberosKeytabLocation
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * The username used to authenticate with the kerberos nodes.          *           * The option is a:<code>java.lang.String</code> type.          *           * Group: security          */
DECL|method|kerberosUsername ( String kerberosUsername)
specifier|default
name|HdfsEndpointProducerBuilder
name|kerberosUsername
parameter_list|(
name|String
name|kerberosUsername
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"kerberosUsername"
argument_list|,
name|kerberosUsername
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
block|}
comment|/**      * Advanced builder for endpoint producers for the HDFS component.      */
DECL|interface|AdvancedHdfsEndpointProducerBuilder
specifier|public
interface|interface
name|AdvancedHdfsEndpointProducerBuilder
extends|extends
name|EndpointProducerBuilder
block|{
DECL|method|basic ()
specifier|default
name|HdfsEndpointProducerBuilder
name|basic
parameter_list|()
block|{
return|return
operator|(
name|HdfsEndpointProducerBuilder
operator|)
name|this
return|;
block|}
comment|/**          * Whether the endpoint should use basic property binding (Camel 2.x) or          * the newer property binding with additional capabilities.          *           * The option is a:<code>boolean</code> type.          *           * Group: advanced          */
DECL|method|basicPropertyBinding ( boolean basicPropertyBinding)
specifier|default
name|AdvancedHdfsEndpointProducerBuilder
name|basicPropertyBinding
parameter_list|(
name|boolean
name|basicPropertyBinding
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"basicPropertyBinding"
argument_list|,
name|basicPropertyBinding
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * Whether the endpoint should use basic property binding (Camel 2.x) or          * the newer property binding with additional capabilities.          *           * The option will be converted to a<code>boolean</code> type.          *           * Group: advanced          */
DECL|method|basicPropertyBinding ( String basicPropertyBinding)
specifier|default
name|AdvancedHdfsEndpointProducerBuilder
name|basicPropertyBinding
parameter_list|(
name|String
name|basicPropertyBinding
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"basicPropertyBinding"
argument_list|,
name|basicPropertyBinding
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * The size of the HDFS blocks.          *           * The option is a:<code>long</code> type.          *           * Group: advanced          */
DECL|method|blockSize (long blockSize)
specifier|default
name|AdvancedHdfsEndpointProducerBuilder
name|blockSize
parameter_list|(
name|long
name|blockSize
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"blockSize"
argument_list|,
name|blockSize
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * The size of the HDFS blocks.          *           * The option will be converted to a<code>long</code> type.          *           * Group: advanced          */
DECL|method|blockSize (String blockSize)
specifier|default
name|AdvancedHdfsEndpointProducerBuilder
name|blockSize
parameter_list|(
name|String
name|blockSize
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"blockSize"
argument_list|,
name|blockSize
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * The buffer size used by HDFS.          *           * The option is a:<code>int</code> type.          *           * Group: advanced          */
DECL|method|bufferSize (int bufferSize)
specifier|default
name|AdvancedHdfsEndpointProducerBuilder
name|bufferSize
parameter_list|(
name|int
name|bufferSize
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"bufferSize"
argument_list|,
name|bufferSize
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * The buffer size used by HDFS.          *           * The option will be converted to a<code>int</code> type.          *           * Group: advanced          */
DECL|method|bufferSize (String bufferSize)
specifier|default
name|AdvancedHdfsEndpointProducerBuilder
name|bufferSize
parameter_list|(
name|String
name|bufferSize
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"bufferSize"
argument_list|,
name|bufferSize
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * How often (time in millis) in to run the idle checker background          * task. This option is only in use if the splitter strategy is IDLE.          *           * The option is a:<code>int</code> type.          *           * Group: advanced          */
DECL|method|checkIdleInterval ( int checkIdleInterval)
specifier|default
name|AdvancedHdfsEndpointProducerBuilder
name|checkIdleInterval
parameter_list|(
name|int
name|checkIdleInterval
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"checkIdleInterval"
argument_list|,
name|checkIdleInterval
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * How often (time in millis) in to run the idle checker background          * task. This option is only in use if the splitter strategy is IDLE.          *           * The option will be converted to a<code>int</code> type.          *           * Group: advanced          */
DECL|method|checkIdleInterval ( String checkIdleInterval)
specifier|default
name|AdvancedHdfsEndpointProducerBuilder
name|checkIdleInterval
parameter_list|(
name|String
name|checkIdleInterval
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"checkIdleInterval"
argument_list|,
name|checkIdleInterval
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * When reading a normal file, this is split into chunks producing a          * message per chunk.          *           * The option is a:<code>int</code> type.          *           * Group: advanced          */
DECL|method|chunkSize (int chunkSize)
specifier|default
name|AdvancedHdfsEndpointProducerBuilder
name|chunkSize
parameter_list|(
name|int
name|chunkSize
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"chunkSize"
argument_list|,
name|chunkSize
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * When reading a normal file, this is split into chunks producing a          * message per chunk.          *           * The option will be converted to a<code>int</code> type.          *           * Group: advanced          */
DECL|method|chunkSize (String chunkSize)
specifier|default
name|AdvancedHdfsEndpointProducerBuilder
name|chunkSize
parameter_list|(
name|String
name|chunkSize
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"chunkSize"
argument_list|,
name|chunkSize
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * The compression codec to use.          *           * The option is a:          *<code>org.apache.camel.component.hdfs.HdfsCompressionCodec</code>          * type.          *           * Group: advanced          */
DECL|method|compressionCodec ( HdfsCompressionCodec compressionCodec)
specifier|default
name|AdvancedHdfsEndpointProducerBuilder
name|compressionCodec
parameter_list|(
name|HdfsCompressionCodec
name|compressionCodec
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"compressionCodec"
argument_list|,
name|compressionCodec
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * The compression codec to use.          *           * The option will be converted to a          *<code>org.apache.camel.component.hdfs.HdfsCompressionCodec</code>          * type.          *           * Group: advanced          */
DECL|method|compressionCodec ( String compressionCodec)
specifier|default
name|AdvancedHdfsEndpointProducerBuilder
name|compressionCodec
parameter_list|(
name|String
name|compressionCodec
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"compressionCodec"
argument_list|,
name|compressionCodec
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * The compression type to use (is default not in use).          *           * The option is a:          *<code>org.apache.hadoop.io.SequenceFile$CompressionType</code> type.          *           * Group: advanced          */
DECL|method|compressionType ( CompressionType compressionType)
specifier|default
name|AdvancedHdfsEndpointProducerBuilder
name|compressionType
parameter_list|(
name|CompressionType
name|compressionType
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"compressionType"
argument_list|,
name|compressionType
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * The compression type to use (is default not in use).          *           * The option will be converted to a          *<code>org.apache.hadoop.io.SequenceFile$CompressionType</code> type.          *           * Group: advanced          */
DECL|method|compressionType ( String compressionType)
specifier|default
name|AdvancedHdfsEndpointProducerBuilder
name|compressionType
parameter_list|(
name|String
name|compressionType
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"compressionType"
argument_list|,
name|compressionType
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * When a file is opened for reading/writing the file is renamed with          * this suffix to avoid to read it during the writing phase.          *           * The option is a:<code>java.lang.String</code> type.          *           * Group: advanced          */
DECL|method|openedSuffix ( String openedSuffix)
specifier|default
name|AdvancedHdfsEndpointProducerBuilder
name|openedSuffix
parameter_list|(
name|String
name|openedSuffix
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"openedSuffix"
argument_list|,
name|openedSuffix
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * Once the file has been read is renamed with this suffix to avoid to          * read it again.          *           * The option is a:<code>java.lang.String</code> type.          *           * Group: advanced          */
DECL|method|readSuffix (String readSuffix)
specifier|default
name|AdvancedHdfsEndpointProducerBuilder
name|readSuffix
parameter_list|(
name|String
name|readSuffix
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"readSuffix"
argument_list|,
name|readSuffix
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * The HDFS replication factor.          *           * The option is a:<code>short</code> type.          *           * Group: advanced          */
DECL|method|replication ( short replication)
specifier|default
name|AdvancedHdfsEndpointProducerBuilder
name|replication
parameter_list|(
name|short
name|replication
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"replication"
argument_list|,
name|replication
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * The HDFS replication factor.          *           * The option will be converted to a<code>short</code> type.          *           * Group: advanced          */
DECL|method|replication ( String replication)
specifier|default
name|AdvancedHdfsEndpointProducerBuilder
name|replication
parameter_list|(
name|String
name|replication
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"replication"
argument_list|,
name|replication
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * In the current version of Hadoop opening a file in append mode is          * disabled since it's not very reliable. So, for the moment, it's only          * possible to create new files. The Camel HDFS endpoint tries to solve          * this problem in this way: If the split strategy option has been          * defined, the hdfs path will be used as a directory and files will be          * created using the configured UuidGenerator. Every time a splitting          * condition is met, a new file is created. The splitStrategy option is          * defined as a string with the following syntax:          * splitStrategy=ST:value,ST:value,... where ST can be: BYTES a new file          * is created, and the old is closed when the number of written bytes is          * more than value MESSAGES a new file is created, and the old is closed          * when the number of written messages is more than value IDLE a new          * file is created, and the old is closed when no writing happened in          * the last value milliseconds.          *           * The option is a:<code>java.lang.String</code> type.          *           * Group: advanced          */
DECL|method|splitStrategy ( String splitStrategy)
specifier|default
name|AdvancedHdfsEndpointProducerBuilder
name|splitStrategy
parameter_list|(
name|String
name|splitStrategy
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"splitStrategy"
argument_list|,
name|splitStrategy
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * Sets whether synchronous processing should be strictly used, or Camel          * is allowed to use asynchronous processing (if supported).          *           * The option is a:<code>boolean</code> type.          *           * Group: advanced          */
DECL|method|synchronous ( boolean synchronous)
specifier|default
name|AdvancedHdfsEndpointProducerBuilder
name|synchronous
parameter_list|(
name|boolean
name|synchronous
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"synchronous"
argument_list|,
name|synchronous
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * Sets whether synchronous processing should be strictly used, or Camel          * is allowed to use asynchronous processing (if supported).          *           * The option will be converted to a<code>boolean</code> type.          *           * Group: advanced          */
DECL|method|synchronous ( String synchronous)
specifier|default
name|AdvancedHdfsEndpointProducerBuilder
name|synchronous
parameter_list|(
name|String
name|synchronous
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"synchronous"
argument_list|,
name|synchronous
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
block|}
comment|/**      * Builder for endpoint for the HDFS component.      */
DECL|interface|HdfsEndpointBuilder
specifier|public
interface|interface
name|HdfsEndpointBuilder
extends|extends
name|HdfsEndpointConsumerBuilder
extends|,
name|HdfsEndpointProducerBuilder
block|{
DECL|method|advanced ()
specifier|default
name|AdvancedHdfsEndpointBuilder
name|advanced
parameter_list|()
block|{
return|return
operator|(
name|AdvancedHdfsEndpointBuilder
operator|)
name|this
return|;
block|}
comment|/**          * Whether to connect to the HDFS file system on starting the          * producer/consumer. If false then the connection is created on-demand.          * Notice that HDFS may take up till 15 minutes to establish a          * connection, as it has hardcoded 45 x 20 sec redelivery. By setting          * this option to false allows your application to startup, and not          * block for up till 15 minutes.          *           * The option is a:<code>boolean</code> type.          *           * Group: common          */
DECL|method|connectOnStartup (boolean connectOnStartup)
specifier|default
name|HdfsEndpointBuilder
name|connectOnStartup
parameter_list|(
name|boolean
name|connectOnStartup
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"connectOnStartup"
argument_list|,
name|connectOnStartup
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * Whether to connect to the HDFS file system on starting the          * producer/consumer. If false then the connection is created on-demand.          * Notice that HDFS may take up till 15 minutes to establish a          * connection, as it has hardcoded 45 x 20 sec redelivery. By setting          * this option to false allows your application to startup, and not          * block for up till 15 minutes.          *           * The option will be converted to a<code>boolean</code> type.          *           * Group: common          */
DECL|method|connectOnStartup (String connectOnStartup)
specifier|default
name|HdfsEndpointBuilder
name|connectOnStartup
parameter_list|(
name|String
name|connectOnStartup
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"connectOnStartup"
argument_list|,
name|connectOnStartup
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * Set to LOCAL to not use HDFS but local java.io.File instead.          *           * The option is a:          *<code>org.apache.camel.component.hdfs.HdfsFileSystemType</code> type.          *           * Group: common          */
DECL|method|fileSystemType ( HdfsFileSystemType fileSystemType)
specifier|default
name|HdfsEndpointBuilder
name|fileSystemType
parameter_list|(
name|HdfsFileSystemType
name|fileSystemType
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"fileSystemType"
argument_list|,
name|fileSystemType
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * Set to LOCAL to not use HDFS but local java.io.File instead.          *           * The option will be converted to a          *<code>org.apache.camel.component.hdfs.HdfsFileSystemType</code> type.          *           * Group: common          */
DECL|method|fileSystemType (String fileSystemType)
specifier|default
name|HdfsEndpointBuilder
name|fileSystemType
parameter_list|(
name|String
name|fileSystemType
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"fileSystemType"
argument_list|,
name|fileSystemType
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * The file type to use. For more details see Hadoop HDFS documentation          * about the various files types.          *           * The option is a:          *<code>org.apache.camel.component.hdfs.HdfsFileType</code> type.          *           * Group: common          */
DECL|method|fileType (HdfsFileType fileType)
specifier|default
name|HdfsEndpointBuilder
name|fileType
parameter_list|(
name|HdfsFileType
name|fileType
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"fileType"
argument_list|,
name|fileType
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * The file type to use. For more details see Hadoop HDFS documentation          * about the various files types.          *           * The option will be converted to a          *<code>org.apache.camel.component.hdfs.HdfsFileType</code> type.          *           * Group: common          */
DECL|method|fileType (String fileType)
specifier|default
name|HdfsEndpointBuilder
name|fileType
parameter_list|(
name|String
name|fileType
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"fileType"
argument_list|,
name|fileType
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * The type for the key in case of sequence or map files.          *           * The option is a:          *<code>org.apache.camel.component.hdfs.WritableType</code> type.          *           * Group: common          */
DECL|method|keyType (WritableType keyType)
specifier|default
name|HdfsEndpointBuilder
name|keyType
parameter_list|(
name|WritableType
name|keyType
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"keyType"
argument_list|,
name|keyType
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * The type for the key in case of sequence or map files.          *           * The option will be converted to a          *<code>org.apache.camel.component.hdfs.WritableType</code> type.          *           * Group: common          */
DECL|method|keyType (String keyType)
specifier|default
name|HdfsEndpointBuilder
name|keyType
parameter_list|(
name|String
name|keyType
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"keyType"
argument_list|,
name|keyType
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * A comma separated list of named nodes (e.g.          * srv11.example.com:8020,srv12.example.com:8020).          *           * The option is a:<code>java.lang.String</code> type.          *           * Group: common          */
DECL|method|namedNodes (String namedNodes)
specifier|default
name|HdfsEndpointBuilder
name|namedNodes
parameter_list|(
name|String
name|namedNodes
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"namedNodes"
argument_list|,
name|namedNodes
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * The file owner must match this owner for the consumer to pickup the          * file. Otherwise the file is skipped.          *           * The option is a:<code>java.lang.String</code> type.          *           * Group: common          */
DECL|method|owner (String owner)
specifier|default
name|HdfsEndpointBuilder
name|owner
parameter_list|(
name|String
name|owner
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"owner"
argument_list|,
name|owner
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * The type for the key in case of sequence or map files.          *           * The option is a:          *<code>org.apache.camel.component.hdfs.WritableType</code> type.          *           * Group: common          */
DECL|method|valueType (WritableType valueType)
specifier|default
name|HdfsEndpointBuilder
name|valueType
parameter_list|(
name|WritableType
name|valueType
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"valueType"
argument_list|,
name|valueType
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * The type for the key in case of sequence or map files.          *           * The option will be converted to a          *<code>org.apache.camel.component.hdfs.WritableType</code> type.          *           * Group: common          */
DECL|method|valueType (String valueType)
specifier|default
name|HdfsEndpointBuilder
name|valueType
parameter_list|(
name|String
name|valueType
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"valueType"
argument_list|,
name|valueType
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * The location of the kerb5.conf file          * (https://web.mit.edu/kerberos/krb5-1.12/doc/admin/conf_files/krb5_conf.html).          *           * The option is a:<code>java.lang.String</code> type.          *           * Group: security          */
DECL|method|kerberosConfigFileLocation ( String kerberosConfigFileLocation)
specifier|default
name|HdfsEndpointBuilder
name|kerberosConfigFileLocation
parameter_list|(
name|String
name|kerberosConfigFileLocation
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"kerberosConfigFileLocation"
argument_list|,
name|kerberosConfigFileLocation
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * The location of the keytab file used to authenticate with the          * kerberos nodes (contains pairs of kerberos principals and encrypted          * keys (which are derived from the Kerberos password)).          *           * The option is a:<code>java.lang.String</code> type.          *           * Group: security          */
DECL|method|kerberosKeytabLocation ( String kerberosKeytabLocation)
specifier|default
name|HdfsEndpointBuilder
name|kerberosKeytabLocation
parameter_list|(
name|String
name|kerberosKeytabLocation
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"kerberosKeytabLocation"
argument_list|,
name|kerberosKeytabLocation
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * The username used to authenticate with the kerberos nodes.          *           * The option is a:<code>java.lang.String</code> type.          *           * Group: security          */
DECL|method|kerberosUsername (String kerberosUsername)
specifier|default
name|HdfsEndpointBuilder
name|kerberosUsername
parameter_list|(
name|String
name|kerberosUsername
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"kerberosUsername"
argument_list|,
name|kerberosUsername
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
block|}
comment|/**      * Advanced builder for endpoint for the HDFS component.      */
DECL|interface|AdvancedHdfsEndpointBuilder
specifier|public
interface|interface
name|AdvancedHdfsEndpointBuilder
extends|extends
name|AdvancedHdfsEndpointConsumerBuilder
extends|,
name|AdvancedHdfsEndpointProducerBuilder
block|{
DECL|method|basic ()
specifier|default
name|HdfsEndpointBuilder
name|basic
parameter_list|()
block|{
return|return
operator|(
name|HdfsEndpointBuilder
operator|)
name|this
return|;
block|}
comment|/**          * Whether the endpoint should use basic property binding (Camel 2.x) or          * the newer property binding with additional capabilities.          *           * The option is a:<code>boolean</code> type.          *           * Group: advanced          */
DECL|method|basicPropertyBinding ( boolean basicPropertyBinding)
specifier|default
name|AdvancedHdfsEndpointBuilder
name|basicPropertyBinding
parameter_list|(
name|boolean
name|basicPropertyBinding
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"basicPropertyBinding"
argument_list|,
name|basicPropertyBinding
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * Whether the endpoint should use basic property binding (Camel 2.x) or          * the newer property binding with additional capabilities.          *           * The option will be converted to a<code>boolean</code> type.          *           * Group: advanced          */
DECL|method|basicPropertyBinding ( String basicPropertyBinding)
specifier|default
name|AdvancedHdfsEndpointBuilder
name|basicPropertyBinding
parameter_list|(
name|String
name|basicPropertyBinding
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"basicPropertyBinding"
argument_list|,
name|basicPropertyBinding
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * The size of the HDFS blocks.          *           * The option is a:<code>long</code> type.          *           * Group: advanced          */
DECL|method|blockSize (long blockSize)
specifier|default
name|AdvancedHdfsEndpointBuilder
name|blockSize
parameter_list|(
name|long
name|blockSize
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"blockSize"
argument_list|,
name|blockSize
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * The size of the HDFS blocks.          *           * The option will be converted to a<code>long</code> type.          *           * Group: advanced          */
DECL|method|blockSize (String blockSize)
specifier|default
name|AdvancedHdfsEndpointBuilder
name|blockSize
parameter_list|(
name|String
name|blockSize
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"blockSize"
argument_list|,
name|blockSize
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * The buffer size used by HDFS.          *           * The option is a:<code>int</code> type.          *           * Group: advanced          */
DECL|method|bufferSize (int bufferSize)
specifier|default
name|AdvancedHdfsEndpointBuilder
name|bufferSize
parameter_list|(
name|int
name|bufferSize
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"bufferSize"
argument_list|,
name|bufferSize
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * The buffer size used by HDFS.          *           * The option will be converted to a<code>int</code> type.          *           * Group: advanced          */
DECL|method|bufferSize (String bufferSize)
specifier|default
name|AdvancedHdfsEndpointBuilder
name|bufferSize
parameter_list|(
name|String
name|bufferSize
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"bufferSize"
argument_list|,
name|bufferSize
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * How often (time in millis) in to run the idle checker background          * task. This option is only in use if the splitter strategy is IDLE.          *           * The option is a:<code>int</code> type.          *           * Group: advanced          */
DECL|method|checkIdleInterval ( int checkIdleInterval)
specifier|default
name|AdvancedHdfsEndpointBuilder
name|checkIdleInterval
parameter_list|(
name|int
name|checkIdleInterval
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"checkIdleInterval"
argument_list|,
name|checkIdleInterval
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * How often (time in millis) in to run the idle checker background          * task. This option is only in use if the splitter strategy is IDLE.          *           * The option will be converted to a<code>int</code> type.          *           * Group: advanced          */
DECL|method|checkIdleInterval ( String checkIdleInterval)
specifier|default
name|AdvancedHdfsEndpointBuilder
name|checkIdleInterval
parameter_list|(
name|String
name|checkIdleInterval
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"checkIdleInterval"
argument_list|,
name|checkIdleInterval
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * When reading a normal file, this is split into chunks producing a          * message per chunk.          *           * The option is a:<code>int</code> type.          *           * Group: advanced          */
DECL|method|chunkSize (int chunkSize)
specifier|default
name|AdvancedHdfsEndpointBuilder
name|chunkSize
parameter_list|(
name|int
name|chunkSize
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"chunkSize"
argument_list|,
name|chunkSize
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * When reading a normal file, this is split into chunks producing a          * message per chunk.          *           * The option will be converted to a<code>int</code> type.          *           * Group: advanced          */
DECL|method|chunkSize (String chunkSize)
specifier|default
name|AdvancedHdfsEndpointBuilder
name|chunkSize
parameter_list|(
name|String
name|chunkSize
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"chunkSize"
argument_list|,
name|chunkSize
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * The compression codec to use.          *           * The option is a:          *<code>org.apache.camel.component.hdfs.HdfsCompressionCodec</code>          * type.          *           * Group: advanced          */
DECL|method|compressionCodec ( HdfsCompressionCodec compressionCodec)
specifier|default
name|AdvancedHdfsEndpointBuilder
name|compressionCodec
parameter_list|(
name|HdfsCompressionCodec
name|compressionCodec
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"compressionCodec"
argument_list|,
name|compressionCodec
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * The compression codec to use.          *           * The option will be converted to a          *<code>org.apache.camel.component.hdfs.HdfsCompressionCodec</code>          * type.          *           * Group: advanced          */
DECL|method|compressionCodec ( String compressionCodec)
specifier|default
name|AdvancedHdfsEndpointBuilder
name|compressionCodec
parameter_list|(
name|String
name|compressionCodec
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"compressionCodec"
argument_list|,
name|compressionCodec
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * The compression type to use (is default not in use).          *           * The option is a:          *<code>org.apache.hadoop.io.SequenceFile$CompressionType</code> type.          *           * Group: advanced          */
DECL|method|compressionType ( CompressionType compressionType)
specifier|default
name|AdvancedHdfsEndpointBuilder
name|compressionType
parameter_list|(
name|CompressionType
name|compressionType
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"compressionType"
argument_list|,
name|compressionType
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * The compression type to use (is default not in use).          *           * The option will be converted to a          *<code>org.apache.hadoop.io.SequenceFile$CompressionType</code> type.          *           * Group: advanced          */
DECL|method|compressionType ( String compressionType)
specifier|default
name|AdvancedHdfsEndpointBuilder
name|compressionType
parameter_list|(
name|String
name|compressionType
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"compressionType"
argument_list|,
name|compressionType
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * When a file is opened for reading/writing the file is renamed with          * this suffix to avoid to read it during the writing phase.          *           * The option is a:<code>java.lang.String</code> type.          *           * Group: advanced          */
DECL|method|openedSuffix (String openedSuffix)
specifier|default
name|AdvancedHdfsEndpointBuilder
name|openedSuffix
parameter_list|(
name|String
name|openedSuffix
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"openedSuffix"
argument_list|,
name|openedSuffix
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * Once the file has been read is renamed with this suffix to avoid to          * read it again.          *           * The option is a:<code>java.lang.String</code> type.          *           * Group: advanced          */
DECL|method|readSuffix (String readSuffix)
specifier|default
name|AdvancedHdfsEndpointBuilder
name|readSuffix
parameter_list|(
name|String
name|readSuffix
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"readSuffix"
argument_list|,
name|readSuffix
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * The HDFS replication factor.          *           * The option is a:<code>short</code> type.          *           * Group: advanced          */
DECL|method|replication (short replication)
specifier|default
name|AdvancedHdfsEndpointBuilder
name|replication
parameter_list|(
name|short
name|replication
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"replication"
argument_list|,
name|replication
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * The HDFS replication factor.          *           * The option will be converted to a<code>short</code> type.          *           * Group: advanced          */
DECL|method|replication (String replication)
specifier|default
name|AdvancedHdfsEndpointBuilder
name|replication
parameter_list|(
name|String
name|replication
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"replication"
argument_list|,
name|replication
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * In the current version of Hadoop opening a file in append mode is          * disabled since it's not very reliable. So, for the moment, it's only          * possible to create new files. The Camel HDFS endpoint tries to solve          * this problem in this way: If the split strategy option has been          * defined, the hdfs path will be used as a directory and files will be          * created using the configured UuidGenerator. Every time a splitting          * condition is met, a new file is created. The splitStrategy option is          * defined as a string with the following syntax:          * splitStrategy=ST:value,ST:value,... where ST can be: BYTES a new file          * is created, and the old is closed when the number of written bytes is          * more than value MESSAGES a new file is created, and the old is closed          * when the number of written messages is more than value IDLE a new          * file is created, and the old is closed when no writing happened in          * the last value milliseconds.          *           * The option is a:<code>java.lang.String</code> type.          *           * Group: advanced          */
DECL|method|splitStrategy (String splitStrategy)
specifier|default
name|AdvancedHdfsEndpointBuilder
name|splitStrategy
parameter_list|(
name|String
name|splitStrategy
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"splitStrategy"
argument_list|,
name|splitStrategy
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * Sets whether synchronous processing should be strictly used, or Camel          * is allowed to use asynchronous processing (if supported).          *           * The option is a:<code>boolean</code> type.          *           * Group: advanced          */
DECL|method|synchronous (boolean synchronous)
specifier|default
name|AdvancedHdfsEndpointBuilder
name|synchronous
parameter_list|(
name|boolean
name|synchronous
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"synchronous"
argument_list|,
name|synchronous
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * Sets whether synchronous processing should be strictly used, or Camel          * is allowed to use asynchronous processing (if supported).          *           * The option will be converted to a<code>boolean</code> type.          *           * Group: advanced          */
DECL|method|synchronous (String synchronous)
specifier|default
name|AdvancedHdfsEndpointBuilder
name|synchronous
parameter_list|(
name|String
name|synchronous
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"synchronous"
argument_list|,
name|synchronous
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
block|}
comment|/**      * Proxy enum for      *<code>org.apache.camel.component.hdfs.HdfsFileSystemType</code> enum.      */
DECL|enum|HdfsFileSystemType
enum|enum
name|HdfsFileSystemType
block|{
DECL|enumConstant|LOCAL
name|LOCAL
block|,
DECL|enumConstant|HDFS
name|HDFS
block|;     }
comment|/**      * Proxy enum for<code>org.apache.camel.component.hdfs.HdfsFileType</code>      * enum.      */
DECL|enum|HdfsFileType
enum|enum
name|HdfsFileType
block|{
DECL|enumConstant|NORMAL_FILE
name|NORMAL_FILE
block|,
DECL|enumConstant|SEQUENCE_FILE
name|SEQUENCE_FILE
block|,
DECL|enumConstant|MAP_FILE
name|MAP_FILE
block|,
DECL|enumConstant|BLOOMMAP_FILE
name|BLOOMMAP_FILE
block|,
DECL|enumConstant|ARRAY_FILE
name|ARRAY_FILE
block|;     }
comment|/**      * Proxy enum for<code>org.apache.camel.component.hdfs.WritableType</code>      * enum.      */
DECL|enum|WritableType
enum|enum
name|WritableType
block|{
DECL|enumConstant|NULL
name|NULL
block|,
DECL|enumConstant|BOOLEAN
name|BOOLEAN
block|,
DECL|enumConstant|BYTE
name|BYTE
block|,
DECL|enumConstant|INT
name|INT
block|,
DECL|enumConstant|FLOAT
name|FLOAT
block|,
DECL|enumConstant|LONG
name|LONG
block|,
DECL|enumConstant|DOUBLE
name|DOUBLE
block|,
DECL|enumConstant|TEXT
name|TEXT
block|,
DECL|enumConstant|BYTES
name|BYTES
block|;     }
comment|/**      * Proxy enum for      *<code>org.apache.camel.component.hdfs.HdfsCompressionCodec</code> enum.      */
DECL|enum|HdfsCompressionCodec
enum|enum
name|HdfsCompressionCodec
block|{
DECL|enumConstant|DEFAULT
name|DEFAULT
block|,
DECL|enumConstant|GZIP
name|GZIP
block|,
DECL|enumConstant|BZIP2
name|BZIP2
block|;     }
comment|/**      * Proxy enum for      *<code>org.apache.hadoop.io.SequenceFile$CompressionType</code> enum.      */
DECL|enum|CompressionType
enum|enum
name|CompressionType
block|{
DECL|enumConstant|NONE
name|NONE
block|,
DECL|enumConstant|RECORD
name|RECORD
block|,
DECL|enumConstant|BLOCK
name|BLOCK
block|;     }
comment|/**      * HDFS (camel-hdfs)      * For reading/writing from/to an HDFS filesystem using Hadoop 2.x.      *       * Category: hadoop,file      * Since: 2.14      * Maven coordinates: org.apache.camel:camel-hdfs      *       * Syntax:<code>hdfs:hostName:port/path</code>      *       * Path parameter: hostName (required)      * HDFS host to use      *       * Path parameter: port      * HDFS port to use      * Default value: 8020      *       * Path parameter: path (required)      * The directory path to use      */
DECL|method|hdfs (String path)
specifier|default
name|HdfsEndpointBuilder
name|hdfs
parameter_list|(
name|String
name|path
parameter_list|)
block|{
class|class
name|HdfsEndpointBuilderImpl
extends|extends
name|AbstractEndpointBuilder
implements|implements
name|HdfsEndpointBuilder
implements|,
name|AdvancedHdfsEndpointBuilder
block|{
specifier|public
name|HdfsEndpointBuilderImpl
parameter_list|(
name|String
name|path
parameter_list|)
block|{
name|super
argument_list|(
literal|"hdfs"
argument_list|,
name|path
argument_list|)
expr_stmt|;
block|}
block|}
return|return
operator|new
name|HdfsEndpointBuilderImpl
argument_list|(
name|path
argument_list|)
return|;
block|}
block|}
end_interface

end_unit

