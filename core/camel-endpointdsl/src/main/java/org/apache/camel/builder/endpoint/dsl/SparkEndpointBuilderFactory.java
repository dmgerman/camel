begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/*  * Licensed to the Apache Software Foundation (ASF) under one or more  * contributor license agreements.  See the NOTICE file distributed with  * this work for additional information regarding copyright ownership.  * The ASF licenses this file to You under the Apache License, Version 2.0  * (the "License"); you may not use this file except in compliance with  * the License.  You may obtain a copy of the License at  *  *      http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
DECL|package|org.apache.camel.builder.endpoint.dsl
package|package
name|org
operator|.
name|apache
operator|.
name|camel
operator|.
name|builder
operator|.
name|endpoint
operator|.
name|dsl
package|;
end_package

begin_import
import|import
name|javax
operator|.
name|annotation
operator|.
name|Generated
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|camel
operator|.
name|builder
operator|.
name|EndpointConsumerBuilder
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|camel
operator|.
name|builder
operator|.
name|EndpointProducerBuilder
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|camel
operator|.
name|builder
operator|.
name|endpoint
operator|.
name|AbstractEndpointBuilder
import|;
end_import

begin_comment
comment|/**  * The spark component can be used to send RDD or DataFrame jobs to Apache Spark  * cluster.  *   * Generated by camel-package-maven-plugin - do not edit this file!  */
end_comment

begin_interface
annotation|@
name|Generated
argument_list|(
literal|"org.apache.camel.maven.packaging.EndpointDslMojo"
argument_list|)
DECL|interface|SparkEndpointBuilderFactory
specifier|public
interface|interface
name|SparkEndpointBuilderFactory
block|{
comment|/**      * Builder for endpoint for the Apache Spark component.      */
DECL|interface|SparkEndpointBuilder
specifier|public
interface|interface
name|SparkEndpointBuilder
extends|extends
name|EndpointProducerBuilder
block|{
DECL|method|advanced ()
specifier|default
name|AdvancedSparkEndpointBuilder
name|advanced
parameter_list|()
block|{
return|return
operator|(
name|AdvancedSparkEndpointBuilder
operator|)
name|this
return|;
block|}
comment|/**          * Indicates if results should be collected or counted.          *           * The option is a:<code>boolean</code> type.          *           * Group: producer          */
DECL|method|collect (boolean collect)
specifier|default
name|SparkEndpointBuilder
name|collect
parameter_list|(
name|boolean
name|collect
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"collect"
argument_list|,
name|collect
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * Indicates if results should be collected or counted.          *           * The option will be converted to a<code>boolean</code> type.          *           * Group: producer          */
DECL|method|collect (String collect)
specifier|default
name|SparkEndpointBuilder
name|collect
parameter_list|(
name|String
name|collect
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"collect"
argument_list|,
name|collect
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * DataFrame to compute against.          *           * The option is a:          *<code>org.apache.spark.sql.Dataset&lt;org.apache.spark.sql.Row&gt;</code> type.          *           * Group: producer          */
DECL|method|dataFrame (Object dataFrame)
specifier|default
name|SparkEndpointBuilder
name|dataFrame
parameter_list|(
name|Object
name|dataFrame
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"dataFrame"
argument_list|,
name|dataFrame
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * DataFrame to compute against.          *           * The option will be converted to a          *<code>org.apache.spark.sql.Dataset&lt;org.apache.spark.sql.Row&gt;</code> type.          *           * Group: producer          */
DECL|method|dataFrame (String dataFrame)
specifier|default
name|SparkEndpointBuilder
name|dataFrame
parameter_list|(
name|String
name|dataFrame
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"dataFrame"
argument_list|,
name|dataFrame
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * Function performing action against an DataFrame.          *           * The option is a:          *<code>org.apache.camel.component.spark.DataFrameCallback</code> type.          *           * Group: producer          */
DECL|method|dataFrameCallback (Object dataFrameCallback)
specifier|default
name|SparkEndpointBuilder
name|dataFrameCallback
parameter_list|(
name|Object
name|dataFrameCallback
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"dataFrameCallback"
argument_list|,
name|dataFrameCallback
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * Function performing action against an DataFrame.          *           * The option will be converted to a          *<code>org.apache.camel.component.spark.DataFrameCallback</code> type.          *           * Group: producer          */
DECL|method|dataFrameCallback (String dataFrameCallback)
specifier|default
name|SparkEndpointBuilder
name|dataFrameCallback
parameter_list|(
name|String
name|dataFrameCallback
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"dataFrameCallback"
argument_list|,
name|dataFrameCallback
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * RDD to compute against.          *           * The option is a:<code>org.apache.spark.api.java.JavaRDDLike</code>          * type.          *           * Group: producer          */
DECL|method|rdd (Object rdd)
specifier|default
name|SparkEndpointBuilder
name|rdd
parameter_list|(
name|Object
name|rdd
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"rdd"
argument_list|,
name|rdd
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * RDD to compute against.          *           * The option will be converted to a          *<code>org.apache.spark.api.java.JavaRDDLike</code> type.          *           * Group: producer          */
DECL|method|rdd (String rdd)
specifier|default
name|SparkEndpointBuilder
name|rdd
parameter_list|(
name|String
name|rdd
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"rdd"
argument_list|,
name|rdd
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * Function performing action against an RDD.          *           * The option is a:          *<code>org.apache.camel.component.spark.RddCallback</code> type.          *           * Group: producer          */
DECL|method|rddCallback (Object rddCallback)
specifier|default
name|SparkEndpointBuilder
name|rddCallback
parameter_list|(
name|Object
name|rddCallback
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"rddCallback"
argument_list|,
name|rddCallback
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * Function performing action against an RDD.          *           * The option will be converted to a          *<code>org.apache.camel.component.spark.RddCallback</code> type.          *           * Group: producer          */
DECL|method|rddCallback (String rddCallback)
specifier|default
name|SparkEndpointBuilder
name|rddCallback
parameter_list|(
name|String
name|rddCallback
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"rddCallback"
argument_list|,
name|rddCallback
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
block|}
comment|/**      * Advanced builder for endpoint for the Apache Spark component.      */
DECL|interface|AdvancedSparkEndpointBuilder
specifier|public
interface|interface
name|AdvancedSparkEndpointBuilder
extends|extends
name|EndpointProducerBuilder
block|{
DECL|method|basic ()
specifier|default
name|SparkEndpointBuilder
name|basic
parameter_list|()
block|{
return|return
operator|(
name|SparkEndpointBuilder
operator|)
name|this
return|;
block|}
comment|/**          * Whether the endpoint should use basic property binding (Camel 2.x) or          * the newer property binding with additional capabilities.          *           * The option is a:<code>boolean</code> type.          *           * Group: advanced          */
DECL|method|basicPropertyBinding ( boolean basicPropertyBinding)
specifier|default
name|AdvancedSparkEndpointBuilder
name|basicPropertyBinding
parameter_list|(
name|boolean
name|basicPropertyBinding
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"basicPropertyBinding"
argument_list|,
name|basicPropertyBinding
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * Whether the endpoint should use basic property binding (Camel 2.x) or          * the newer property binding with additional capabilities.          *           * The option will be converted to a<code>boolean</code> type.          *           * Group: advanced          */
DECL|method|basicPropertyBinding ( String basicPropertyBinding)
specifier|default
name|AdvancedSparkEndpointBuilder
name|basicPropertyBinding
parameter_list|(
name|String
name|basicPropertyBinding
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"basicPropertyBinding"
argument_list|,
name|basicPropertyBinding
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * Sets whether synchronous processing should be strictly used, or Camel          * is allowed to use asynchronous processing (if supported).          *           * The option is a:<code>boolean</code> type.          *           * Group: advanced          */
DECL|method|synchronous (boolean synchronous)
specifier|default
name|AdvancedSparkEndpointBuilder
name|synchronous
parameter_list|(
name|boolean
name|synchronous
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"synchronous"
argument_list|,
name|synchronous
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**          * Sets whether synchronous processing should be strictly used, or Camel          * is allowed to use asynchronous processing (if supported).          *           * The option will be converted to a<code>boolean</code> type.          *           * Group: advanced          */
DECL|method|synchronous (String synchronous)
specifier|default
name|AdvancedSparkEndpointBuilder
name|synchronous
parameter_list|(
name|String
name|synchronous
parameter_list|)
block|{
name|doSetProperty
argument_list|(
literal|"synchronous"
argument_list|,
name|synchronous
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
block|}
comment|/**      * Apache Spark (camel-spark)      * The spark component can be used to send RDD or DataFrame jobs to Apache      * Spark cluster.      *       * Category: bigdata,iot      * Available as of version: 2.17      * Maven coordinates: org.apache.camel:camel-spark      *       * Syntax:<code>spark:endpointType</code>      *       * Path parameter: endpointType (required)      * Type of the endpoint (rdd, dataframe, hive).      * The value can be one of: rdd, dataframe, hive      */
DECL|method|spark (String path)
specifier|default
name|SparkEndpointBuilder
name|spark
parameter_list|(
name|String
name|path
parameter_list|)
block|{
class|class
name|SparkEndpointBuilderImpl
extends|extends
name|AbstractEndpointBuilder
implements|implements
name|SparkEndpointBuilder
implements|,
name|AdvancedSparkEndpointBuilder
block|{
specifier|public
name|SparkEndpointBuilderImpl
parameter_list|(
name|String
name|path
parameter_list|)
block|{
name|super
argument_list|(
literal|"spark"
argument_list|,
name|path
argument_list|)
expr_stmt|;
block|}
block|}
return|return
operator|new
name|SparkEndpointBuilderImpl
argument_list|(
name|path
argument_list|)
return|;
block|}
block|}
end_interface

end_unit

