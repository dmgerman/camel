begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/*  * Licensed to the Apache Software Foundation (ASF) under one or more  * contributor license agreements.  See the NOTICE file distributed with  * this work for additional information regarding copyright ownership.  * The ASF licenses this file to You under the Apache License, Version 2.0  * (the "License"); you may not use this file except in compliance with  * the License.  You may obtain a copy of the License at  *  *      http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
DECL|package|org.apache.camel.component.hdfs
package|package
name|org
operator|.
name|apache
operator|.
name|camel
operator|.
name|component
operator|.
name|hdfs
package|;
end_package

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|stream
operator|.
name|Collectors
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|lang
operator|.
name|StringUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|conf
operator|.
name|Configuration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|DFSConfigKeys
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|DFSUtil
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|server
operator|.
name|namenode
operator|.
name|ha
operator|.
name|ConfiguredFailoverProxyProvider
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|DFSConfigKeys
operator|.
name|DFS_CLIENT_FAILOVER_PROXY_PROVIDER_KEY_PREFIX
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|DFSConfigKeys
operator|.
name|DFS_HA_NAMENODES_KEY_PREFIX
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|DFSConfigKeys
operator|.
name|DFS_NAMENODE_RPC_ADDRESS_KEY
import|;
end_import

begin_class
DECL|class|HaConfigurationBuilder
specifier|final
class|class
name|HaConfigurationBuilder
block|{
DECL|field|HFDS_NAMED_SERVICE
specifier|private
specifier|static
specifier|final
name|String
name|HFDS_NAMED_SERVICE
init|=
literal|"hfdsNamedService"
decl_stmt|;
DECL|field|HFDS_NAMED_SERVICE_SEPARATOR
specifier|private
specifier|static
specifier|final
name|String
name|HFDS_NAMED_SERVICE_SEPARATOR
init|=
literal|"_"
decl_stmt|;
DECL|field|HFDS_FS
specifier|private
specifier|static
specifier|final
name|String
name|HFDS_FS
init|=
literal|"fs.defaultFS"
decl_stmt|;
DECL|method|HaConfigurationBuilder ()
specifier|private
name|HaConfigurationBuilder
parameter_list|()
block|{
comment|// hidden
block|}
comment|/**      * Generates the correct HA configuration (normally read from xml) based on the namedNodes:      * All named nodes have to be qualified: configuration.set("dfs.ha.namenodes.hfdsNamedService","namenode1,namenode2");      * For each named node the following entries is added      *<p>      * configuration.set("dfs.namenode.rpc-address.hfdsNamedService.namenode1", "namenode1:1234");      *<p>      * Finally the proxy provider has to be specified:      *<p>      * configuration.set("dfs.client.failover.proxy.provider.hfdsNamedService", "org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider");      *<p>      *      * @param configuration  - hdfs configuration that will be setup with the HA settings      * @param endpointConfig - configuration with the HA settings configured on the endpoint      */
DECL|method|withClusterConfiguration (Configuration configuration, HdfsConfiguration endpointConfig)
specifier|static
name|void
name|withClusterConfiguration
parameter_list|(
name|Configuration
name|configuration
parameter_list|,
name|HdfsConfiguration
name|endpointConfig
parameter_list|)
block|{
name|String
name|haNamedService
init|=
name|getSanitizedClusterName
argument_list|(
name|endpointConfig
operator|.
name|getHostName
argument_list|()
argument_list|)
decl_stmt|;
name|withClusterConfiguration
argument_list|(
name|configuration
argument_list|,
name|haNamedService
argument_list|,
name|endpointConfig
operator|.
name|getNamedNodeList
argument_list|()
argument_list|,
name|endpointConfig
operator|.
name|getReplication
argument_list|()
argument_list|)
expr_stmt|;
block|}
comment|/**      * Generates the correct HA configuration (normally read from xml) based on the namedNodes:      * All named nodes have to be qualified: configuration.set("dfs.ha.namenodes.hfdsNamedService","namenode1,namenode2");      * For each named node the following entries is added      *<p>      * configuration.set("dfs.namenode.rpc-address.hfdsNamedService.namenode1", "namenode1:1234");      *<p>      * Finally the proxy provider has to be specified:      *<p>      * configuration.set("dfs.client.failover.proxy.provider.hfdsNamedService", "org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider");      *<p>      *      * @param configuration     - hdfs configuration that will be setup with the HA settings      * @param haNamedService    - how the ha named service that represents the cluster will be named (used to resolve the FS)      * @param namedNodes        - All named nodes from the hadoop cluster      * @param replicationFactor - dfs replication factor      */
DECL|method|withClusterConfiguration (Configuration configuration, String haNamedService, List<String> namedNodes, int replicationFactor)
specifier|static
name|void
name|withClusterConfiguration
parameter_list|(
name|Configuration
name|configuration
parameter_list|,
name|String
name|haNamedService
parameter_list|,
name|List
argument_list|<
name|String
argument_list|>
name|namedNodes
parameter_list|,
name|int
name|replicationFactor
parameter_list|)
block|{
name|configuration
operator|.
name|set
argument_list|(
name|DFSConfigKeys
operator|.
name|DFS_REPLICATION_KEY
argument_list|,
name|Integer
operator|.
name|toString
argument_list|(
name|replicationFactor
argument_list|)
argument_list|)
expr_stmt|;
name|configuration
operator|.
name|set
argument_list|(
name|DFSConfigKeys
operator|.
name|DFS_NAMESERVICES
argument_list|,
name|haNamedService
argument_list|)
expr_stmt|;
name|configuration
operator|.
name|set
argument_list|(
name|DFSUtil
operator|.
name|addKeySuffixes
argument_list|(
name|DFS_HA_NAMENODES_KEY_PREFIX
argument_list|,
name|haNamedService
argument_list|)
argument_list|,
name|nodeToString
argument_list|(
name|namedNodes
operator|.
name|stream
argument_list|()
operator|.
name|map
argument_list|(
name|HaConfigurationBuilder
operator|::
name|nodeToString
argument_list|)
operator|.
name|collect
argument_list|(
name|Collectors
operator|.
name|joining
argument_list|(
literal|","
argument_list|)
argument_list|)
argument_list|)
argument_list|)
expr_stmt|;
name|namedNodes
operator|.
name|forEach
argument_list|(
name|nodeName
lambda|->
name|configuration
operator|.
name|set
argument_list|(
name|DFSUtil
operator|.
name|addKeySuffixes
argument_list|(
name|DFS_NAMENODE_RPC_ADDRESS_KEY
argument_list|,
name|haNamedService
argument_list|,
name|nodeToString
argument_list|(
name|nodeName
argument_list|)
argument_list|)
argument_list|,
name|nodeName
argument_list|)
argument_list|)
expr_stmt|;
name|configuration
operator|.
name|set
argument_list|(
name|DFS_CLIENT_FAILOVER_PROXY_PROVIDER_KEY_PREFIX
operator|+
literal|"."
operator|+
name|haNamedService
argument_list|,
name|ConfiguredFailoverProxyProvider
operator|.
name|class
operator|.
name|getName
argument_list|()
argument_list|)
expr_stmt|;
name|configuration
operator|.
name|set
argument_list|(
name|HFDS_FS
argument_list|,
literal|"hdfs://"
operator|+
name|haNamedService
argument_list|)
expr_stmt|;
block|}
DECL|method|getSanitizedClusterName (String rawClusterName)
specifier|static
name|String
name|getSanitizedClusterName
parameter_list|(
name|String
name|rawClusterName
parameter_list|)
block|{
name|String
name|clusterName
init|=
name|HFDS_NAMED_SERVICE
decl_stmt|;
if|if
condition|(
name|StringUtils
operator|.
name|isNotEmpty
argument_list|(
name|rawClusterName
argument_list|)
condition|)
block|{
name|clusterName
operator|=
name|rawClusterName
operator|.
name|replaceAll
argument_list|(
literal|"\\."
argument_list|,
name|HFDS_NAMED_SERVICE_SEPARATOR
argument_list|)
expr_stmt|;
block|}
return|return
name|clusterName
return|;
block|}
DECL|method|nodeToString (String nodeName)
specifier|private
specifier|static
name|String
name|nodeToString
parameter_list|(
name|String
name|nodeName
parameter_list|)
block|{
return|return
name|nodeName
operator|.
name|replaceAll
argument_list|(
literal|":[0-9]*"
argument_list|,
literal|""
argument_list|)
operator|.
name|replaceAll
argument_list|(
literal|"\\."
argument_list|,
name|HFDS_NAMED_SERVICE_SEPARATOR
argument_list|)
return|;
block|}
block|}
end_class

end_unit

