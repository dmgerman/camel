begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/*  * Licensed to the Apache Software Foundation (ASF) under one or more  * contributor license agreements.  See the NOTICE file distributed with  * this work for additional information regarding copyright ownership.  * The ASF licenses this file to You under the Apache License, Version 2.0  * (the "License"); you may not use this file except in compliance with  * the License.  You may obtain a copy of the License at  *  *      http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
DECL|package|org.apache.camel.component.kafka
package|package
name|org
operator|.
name|apache
operator|.
name|camel
operator|.
name|component
operator|.
name|kafka
package|;
end_package

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|ArrayList
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Arrays
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Collection
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Collections
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Iterator
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Properties
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Set
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|UUID
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|ExecutorService
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|regex
operator|.
name|Pattern
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|stream
operator|.
name|StreamSupport
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|camel
operator|.
name|Exchange
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|camel
operator|.
name|Processor
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|camel
operator|.
name|component
operator|.
name|kafka
operator|.
name|serde
operator|.
name|KafkaHeaderDeserializer
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|camel
operator|.
name|spi
operator|.
name|HeaderFilterStrategy
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|camel
operator|.
name|spi
operator|.
name|StateRepository
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|camel
operator|.
name|support
operator|.
name|DefaultConsumer
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|camel
operator|.
name|support
operator|.
name|service
operator|.
name|ServiceHelper
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|camel
operator|.
name|support
operator|.
name|service
operator|.
name|ServiceSupport
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|camel
operator|.
name|util
operator|.
name|IOHelper
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|camel
operator|.
name|util
operator|.
name|ObjectHelper
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|kafka
operator|.
name|clients
operator|.
name|consumer
operator|.
name|ConsumerConfig
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|kafka
operator|.
name|clients
operator|.
name|consumer
operator|.
name|ConsumerRebalanceListener
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|kafka
operator|.
name|clients
operator|.
name|consumer
operator|.
name|ConsumerRecord
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|kafka
operator|.
name|clients
operator|.
name|consumer
operator|.
name|ConsumerRecords
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|kafka
operator|.
name|clients
operator|.
name|consumer
operator|.
name|OffsetAndMetadata
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|kafka
operator|.
name|common
operator|.
name|KafkaException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|kafka
operator|.
name|common
operator|.
name|TopicPartition
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|kafka
operator|.
name|common
operator|.
name|errors
operator|.
name|InterruptException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|kafka
operator|.
name|common
operator|.
name|header
operator|.
name|Header
import|;
end_import

begin_class
DECL|class|KafkaConsumer
specifier|public
class|class
name|KafkaConsumer
extends|extends
name|DefaultConsumer
block|{
DECL|field|executor
specifier|protected
name|ExecutorService
name|executor
decl_stmt|;
DECL|field|endpoint
specifier|private
specifier|final
name|KafkaEndpoint
name|endpoint
decl_stmt|;
DECL|field|processor
specifier|private
specifier|final
name|Processor
name|processor
decl_stmt|;
DECL|field|pollTimeoutMs
specifier|private
specifier|final
name|Long
name|pollTimeoutMs
decl_stmt|;
comment|// This list helps working around the infinite loop of KAFKA-1894
DECL|field|tasks
specifier|private
specifier|final
name|List
argument_list|<
name|KafkaFetchRecords
argument_list|>
name|tasks
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|()
decl_stmt|;
DECL|field|stopOffsetRepo
specifier|private
specifier|volatile
name|boolean
name|stopOffsetRepo
decl_stmt|;
DECL|method|KafkaConsumer (KafkaEndpoint endpoint, Processor processor)
specifier|public
name|KafkaConsumer
parameter_list|(
name|KafkaEndpoint
name|endpoint
parameter_list|,
name|Processor
name|processor
parameter_list|)
block|{
name|super
argument_list|(
name|endpoint
argument_list|,
name|processor
argument_list|)
expr_stmt|;
name|this
operator|.
name|endpoint
operator|=
name|endpoint
expr_stmt|;
name|this
operator|.
name|processor
operator|=
name|processor
expr_stmt|;
name|this
operator|.
name|pollTimeoutMs
operator|=
name|endpoint
operator|.
name|getConfiguration
argument_list|()
operator|.
name|getPollTimeoutMs
argument_list|()
expr_stmt|;
comment|// brokers can be configured on endpoint or component level
name|String
name|brokers
init|=
name|endpoint
operator|.
name|getConfiguration
argument_list|()
operator|.
name|getBrokers
argument_list|()
decl_stmt|;
if|if
condition|(
name|brokers
operator|==
literal|null
condition|)
block|{
name|brokers
operator|=
name|endpoint
operator|.
name|getComponent
argument_list|()
operator|.
name|getBrokers
argument_list|()
expr_stmt|;
block|}
if|if
condition|(
name|ObjectHelper
operator|.
name|isEmpty
argument_list|(
name|brokers
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"Brokers must be configured"
argument_list|)
throw|;
block|}
block|}
DECL|method|getProps ()
name|Properties
name|getProps
parameter_list|()
block|{
name|Properties
name|props
init|=
name|endpoint
operator|.
name|getConfiguration
argument_list|()
operator|.
name|createConsumerProperties
argument_list|()
decl_stmt|;
name|endpoint
operator|.
name|updateClassProperties
argument_list|(
name|props
argument_list|)
expr_stmt|;
comment|// brokers can be configured on endpoint or component level
name|String
name|brokers
init|=
name|endpoint
operator|.
name|getConfiguration
argument_list|()
operator|.
name|getBrokers
argument_list|()
decl_stmt|;
if|if
condition|(
name|brokers
operator|==
literal|null
condition|)
block|{
name|brokers
operator|=
name|endpoint
operator|.
name|getComponent
argument_list|()
operator|.
name|getBrokers
argument_list|()
expr_stmt|;
block|}
if|if
condition|(
name|brokers
operator|==
literal|null
condition|)
block|{
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"URL to the Kafka brokers must be configured with the brokers option on either the component or endpoint."
argument_list|)
throw|;
block|}
name|props
operator|.
name|put
argument_list|(
name|ConsumerConfig
operator|.
name|BOOTSTRAP_SERVERS_CONFIG
argument_list|,
name|brokers
argument_list|)
expr_stmt|;
if|if
condition|(
name|endpoint
operator|.
name|getConfiguration
argument_list|()
operator|.
name|getGroupId
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|String
name|groupId
init|=
name|endpoint
operator|.
name|getConfiguration
argument_list|()
operator|.
name|getGroupId
argument_list|()
decl_stmt|;
name|props
operator|.
name|put
argument_list|(
name|ConsumerConfig
operator|.
name|GROUP_ID_CONFIG
argument_list|,
name|groupId
argument_list|)
expr_stmt|;
name|log
operator|.
name|debug
argument_list|(
literal|"Kafka consumer groupId is {}"
argument_list|,
name|groupId
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|String
name|randomGroupId
init|=
name|UUID
operator|.
name|randomUUID
argument_list|()
operator|.
name|toString
argument_list|()
decl_stmt|;
name|props
operator|.
name|put
argument_list|(
name|ConsumerConfig
operator|.
name|GROUP_ID_CONFIG
argument_list|,
name|randomGroupId
argument_list|)
expr_stmt|;
name|log
operator|.
name|debug
argument_list|(
literal|"Kafka consumer groupId is {} (generated)"
argument_list|,
name|randomGroupId
argument_list|)
expr_stmt|;
block|}
return|return
name|props
return|;
block|}
annotation|@
name|Override
DECL|method|doStart ()
specifier|protected
name|void
name|doStart
parameter_list|()
throws|throws
name|Exception
block|{
name|log
operator|.
name|info
argument_list|(
literal|"Starting Kafka consumer on topic: {} with breakOnFirstError: {}"
argument_list|,
name|endpoint
operator|.
name|getConfiguration
argument_list|()
operator|.
name|getTopic
argument_list|()
argument_list|,
name|endpoint
operator|.
name|getConfiguration
argument_list|()
operator|.
name|isBreakOnFirstError
argument_list|()
argument_list|)
expr_stmt|;
name|super
operator|.
name|doStart
argument_list|()
expr_stmt|;
comment|// is the offset repository already started?
name|StateRepository
name|repo
init|=
name|endpoint
operator|.
name|getConfiguration
argument_list|()
operator|.
name|getOffsetRepository
argument_list|()
decl_stmt|;
if|if
condition|(
name|repo
operator|instanceof
name|ServiceSupport
condition|)
block|{
name|boolean
name|started
init|=
operator|(
operator|(
name|ServiceSupport
operator|)
name|repo
operator|)
operator|.
name|isStarted
argument_list|()
decl_stmt|;
comment|// if not already started then we would do that and also stop it
if|if
condition|(
operator|!
name|started
condition|)
block|{
name|stopOffsetRepo
operator|=
literal|true
expr_stmt|;
name|log
operator|.
name|debug
argument_list|(
literal|"Starting OffsetRepository: {}"
argument_list|,
name|repo
argument_list|)
expr_stmt|;
name|ServiceHelper
operator|.
name|startService
argument_list|(
name|endpoint
operator|.
name|getConfiguration
argument_list|()
operator|.
name|getOffsetRepository
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
name|executor
operator|=
name|endpoint
operator|.
name|createExecutor
argument_list|()
expr_stmt|;
name|String
name|topic
init|=
name|endpoint
operator|.
name|getConfiguration
argument_list|()
operator|.
name|getTopic
argument_list|()
decl_stmt|;
name|Pattern
name|pattern
init|=
literal|null
decl_stmt|;
if|if
condition|(
name|endpoint
operator|.
name|getConfiguration
argument_list|()
operator|.
name|isTopicIsPattern
argument_list|()
condition|)
block|{
name|pattern
operator|=
name|Pattern
operator|.
name|compile
argument_list|(
name|topic
argument_list|)
expr_stmt|;
block|}
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|endpoint
operator|.
name|getConfiguration
argument_list|()
operator|.
name|getConsumersCount
argument_list|()
condition|;
name|i
operator|++
control|)
block|{
name|KafkaFetchRecords
name|task
init|=
operator|new
name|KafkaFetchRecords
argument_list|(
name|topic
argument_list|,
name|pattern
argument_list|,
name|i
operator|+
literal|""
argument_list|,
name|getProps
argument_list|()
argument_list|)
decl_stmt|;
comment|// pre-initialize task during startup so if there is any error we have it thrown asap
name|task
operator|.
name|preInit
argument_list|()
expr_stmt|;
name|executor
operator|.
name|submit
argument_list|(
name|task
argument_list|)
expr_stmt|;
name|tasks
operator|.
name|add
argument_list|(
name|task
argument_list|)
expr_stmt|;
block|}
block|}
annotation|@
name|Override
DECL|method|doStop ()
specifier|protected
name|void
name|doStop
parameter_list|()
throws|throws
name|Exception
block|{
name|log
operator|.
name|info
argument_list|(
literal|"Stopping Kafka consumer on topic: {}"
argument_list|,
name|endpoint
operator|.
name|getConfiguration
argument_list|()
operator|.
name|getTopic
argument_list|()
argument_list|)
expr_stmt|;
if|if
condition|(
name|executor
operator|!=
literal|null
condition|)
block|{
if|if
condition|(
name|getEndpoint
argument_list|()
operator|!=
literal|null
operator|&&
name|getEndpoint
argument_list|()
operator|.
name|getCamelContext
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|getEndpoint
argument_list|()
operator|.
name|getCamelContext
argument_list|()
operator|.
name|getExecutorServiceManager
argument_list|()
operator|.
name|shutdownGraceful
argument_list|(
name|executor
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|executor
operator|.
name|shutdownNow
argument_list|()
expr_stmt|;
block|}
if|if
condition|(
operator|!
name|executor
operator|.
name|isTerminated
argument_list|()
condition|)
block|{
name|tasks
operator|.
name|forEach
argument_list|(
name|KafkaFetchRecords
operator|::
name|shutdown
argument_list|)
expr_stmt|;
name|executor
operator|.
name|shutdownNow
argument_list|()
expr_stmt|;
block|}
block|}
name|tasks
operator|.
name|clear
argument_list|()
expr_stmt|;
name|executor
operator|=
literal|null
expr_stmt|;
if|if
condition|(
name|stopOffsetRepo
condition|)
block|{
name|StateRepository
name|repo
init|=
name|endpoint
operator|.
name|getConfiguration
argument_list|()
operator|.
name|getOffsetRepository
argument_list|()
decl_stmt|;
name|log
operator|.
name|debug
argument_list|(
literal|"Stopping OffsetRepository: {}"
argument_list|,
name|repo
argument_list|)
expr_stmt|;
name|ServiceHelper
operator|.
name|stopAndShutdownService
argument_list|(
name|repo
argument_list|)
expr_stmt|;
block|}
name|super
operator|.
name|doStop
argument_list|()
expr_stmt|;
block|}
DECL|class|KafkaFetchRecords
class|class
name|KafkaFetchRecords
implements|implements
name|Runnable
implements|,
name|ConsumerRebalanceListener
block|{
DECL|field|consumer
specifier|private
name|org
operator|.
name|apache
operator|.
name|kafka
operator|.
name|clients
operator|.
name|consumer
operator|.
name|KafkaConsumer
name|consumer
decl_stmt|;
DECL|field|topicName
specifier|private
specifier|final
name|String
name|topicName
decl_stmt|;
DECL|field|topicPattern
specifier|private
specifier|final
name|Pattern
name|topicPattern
decl_stmt|;
DECL|field|threadId
specifier|private
specifier|final
name|String
name|threadId
decl_stmt|;
DECL|field|kafkaProps
specifier|private
specifier|final
name|Properties
name|kafkaProps
decl_stmt|;
DECL|method|KafkaFetchRecords (String topicName, Pattern topicPattern, String id, Properties kafkaProps)
name|KafkaFetchRecords
parameter_list|(
name|String
name|topicName
parameter_list|,
name|Pattern
name|topicPattern
parameter_list|,
name|String
name|id
parameter_list|,
name|Properties
name|kafkaProps
parameter_list|)
block|{
name|this
operator|.
name|topicName
operator|=
name|topicName
expr_stmt|;
name|this
operator|.
name|topicPattern
operator|=
name|topicPattern
expr_stmt|;
name|this
operator|.
name|threadId
operator|=
name|topicName
operator|+
literal|"-"
operator|+
literal|"Thread "
operator|+
name|id
expr_stmt|;
name|this
operator|.
name|kafkaProps
operator|=
name|kafkaProps
expr_stmt|;
block|}
annotation|@
name|Override
DECL|method|run ()
specifier|public
name|void
name|run
parameter_list|()
block|{
name|boolean
name|first
init|=
literal|true
decl_stmt|;
name|boolean
name|reConnect
init|=
literal|true
decl_stmt|;
while|while
condition|(
name|reConnect
condition|)
block|{
try|try
block|{
if|if
condition|(
operator|!
name|first
condition|)
block|{
comment|// re-initialize on re-connect so we have a fresh consumer
name|doInit
argument_list|()
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|Throwable
name|e
parameter_list|)
block|{
comment|// ensure this is logged so users can see the problem
name|log
operator|.
name|warn
argument_list|(
literal|"Error creating org.apache.kafka.clients.consumer.KafkaConsumer due {}"
argument_list|,
name|e
operator|.
name|getMessage
argument_list|()
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
operator|!
name|first
condition|)
block|{
comment|// skip one poll timeout before trying again
name|long
name|delay
init|=
name|endpoint
operator|.
name|getConfiguration
argument_list|()
operator|.
name|getPollTimeoutMs
argument_list|()
decl_stmt|;
name|log
operator|.
name|info
argument_list|(
literal|"Reconnecting {} to topic {} after {} ms"
argument_list|,
name|threadId
argument_list|,
name|topicName
argument_list|,
name|delay
argument_list|)
expr_stmt|;
try|try
block|{
name|Thread
operator|.
name|sleep
argument_list|(
name|delay
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|e
parameter_list|)
block|{
name|Thread
operator|.
name|currentThread
argument_list|()
operator|.
name|interrupt
argument_list|()
expr_stmt|;
block|}
block|}
name|first
operator|=
literal|false
expr_stmt|;
comment|// doRun keeps running until we either shutdown or is told to re-connect
name|reConnect
operator|=
name|doRun
argument_list|()
expr_stmt|;
block|}
block|}
DECL|method|preInit ()
name|void
name|preInit
parameter_list|()
block|{
name|doInit
argument_list|()
expr_stmt|;
block|}
DECL|method|doInit ()
specifier|protected
name|void
name|doInit
parameter_list|()
block|{
comment|// create consumer
name|ClassLoader
name|threadClassLoader
init|=
name|Thread
operator|.
name|currentThread
argument_list|()
operator|.
name|getContextClassLoader
argument_list|()
decl_stmt|;
try|try
block|{
comment|// Kafka uses reflection for loading authentication settings, use its classloader
name|Thread
operator|.
name|currentThread
argument_list|()
operator|.
name|setContextClassLoader
argument_list|(
name|org
operator|.
name|apache
operator|.
name|kafka
operator|.
name|clients
operator|.
name|consumer
operator|.
name|KafkaConsumer
operator|.
name|class
operator|.
name|getClassLoader
argument_list|()
argument_list|)
expr_stmt|;
comment|// this may throw an exception if something is wrong with kafka consumer
name|this
operator|.
name|consumer
operator|=
operator|new
name|org
operator|.
name|apache
operator|.
name|kafka
operator|.
name|clients
operator|.
name|consumer
operator|.
name|KafkaConsumer
argument_list|(
name|kafkaProps
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|Thread
operator|.
name|currentThread
argument_list|()
operator|.
name|setContextClassLoader
argument_list|(
name|threadClassLoader
argument_list|)
expr_stmt|;
block|}
block|}
annotation|@
name|SuppressWarnings
argument_list|(
literal|"unchecked"
argument_list|)
DECL|method|doRun ()
specifier|protected
name|boolean
name|doRun
parameter_list|()
block|{
comment|// allow to re-connect thread in case we use that to retry failed messages
name|boolean
name|reConnect
init|=
literal|false
decl_stmt|;
name|boolean
name|unsubscribing
init|=
literal|false
decl_stmt|;
try|try
block|{
if|if
condition|(
name|topicPattern
operator|!=
literal|null
condition|)
block|{
name|log
operator|.
name|info
argument_list|(
literal|"Subscribing {} to topic pattern {}"
argument_list|,
name|threadId
argument_list|,
name|topicName
argument_list|)
expr_stmt|;
name|consumer
operator|.
name|subscribe
argument_list|(
name|topicPattern
argument_list|,
name|this
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|log
operator|.
name|info
argument_list|(
literal|"Subscribing {} to topic {}"
argument_list|,
name|threadId
argument_list|,
name|topicName
argument_list|)
expr_stmt|;
name|consumer
operator|.
name|subscribe
argument_list|(
name|Arrays
operator|.
name|asList
argument_list|(
name|topicName
operator|.
name|split
argument_list|(
literal|","
argument_list|)
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|StateRepository
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|offsetRepository
init|=
name|endpoint
operator|.
name|getConfiguration
argument_list|()
operator|.
name|getOffsetRepository
argument_list|()
decl_stmt|;
if|if
condition|(
name|offsetRepository
operator|!=
literal|null
condition|)
block|{
comment|// This poll to ensures we have an assigned partition otherwise seek won't work
name|ConsumerRecords
name|poll
init|=
name|consumer
operator|.
name|poll
argument_list|(
literal|100
argument_list|)
decl_stmt|;
for|for
control|(
name|TopicPartition
name|topicPartition
range|:
operator|(
name|Set
argument_list|<
name|TopicPartition
argument_list|>
operator|)
name|consumer
operator|.
name|assignment
argument_list|()
control|)
block|{
name|String
name|offsetState
init|=
name|offsetRepository
operator|.
name|getState
argument_list|(
name|serializeOffsetKey
argument_list|(
name|topicPartition
argument_list|)
argument_list|)
decl_stmt|;
if|if
condition|(
name|offsetState
operator|!=
literal|null
operator|&&
operator|!
name|offsetState
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
comment|// The state contains the last read offset so you need to seek from the next one
name|long
name|offset
init|=
name|deserializeOffsetValue
argument_list|(
name|offsetState
argument_list|)
operator|+
literal|1
decl_stmt|;
name|log
operator|.
name|debug
argument_list|(
literal|"Resuming partition {} from offset {} from state"
argument_list|,
name|topicPartition
operator|.
name|partition
argument_list|()
argument_list|,
name|offset
argument_list|)
expr_stmt|;
name|consumer
operator|.
name|seek
argument_list|(
name|topicPartition
argument_list|,
name|offset
argument_list|)
expr_stmt|;
block|}
else|else
block|{
comment|// If the init poll has returned some data of a currently unknown topic/partition in the state
comment|// then resume from their offset in order to avoid losing data
name|List
argument_list|<
name|ConsumerRecord
argument_list|<
name|Object
argument_list|,
name|Object
argument_list|>
argument_list|>
name|partitionRecords
init|=
name|poll
operator|.
name|records
argument_list|(
name|topicPartition
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|partitionRecords
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|long
name|offset
init|=
name|partitionRecords
operator|.
name|get
argument_list|(
literal|0
argument_list|)
operator|.
name|offset
argument_list|()
decl_stmt|;
name|log
operator|.
name|debug
argument_list|(
literal|"Resuming partition {} from offset {}"
argument_list|,
name|topicPartition
operator|.
name|partition
argument_list|()
argument_list|,
name|offset
argument_list|)
expr_stmt|;
name|consumer
operator|.
name|seek
argument_list|(
name|topicPartition
argument_list|,
name|offset
argument_list|)
expr_stmt|;
block|}
block|}
block|}
block|}
elseif|else
if|if
condition|(
name|endpoint
operator|.
name|getConfiguration
argument_list|()
operator|.
name|getSeekTo
argument_list|()
operator|!=
literal|null
condition|)
block|{
if|if
condition|(
name|endpoint
operator|.
name|getConfiguration
argument_list|()
operator|.
name|getSeekTo
argument_list|()
operator|.
name|equals
argument_list|(
literal|"beginning"
argument_list|)
condition|)
block|{
name|log
operator|.
name|debug
argument_list|(
literal|"{} is seeking to the beginning on topic {}"
argument_list|,
name|threadId
argument_list|,
name|topicName
argument_list|)
expr_stmt|;
comment|// This poll to ensures we have an assigned partition otherwise seek won't work
name|consumer
operator|.
name|poll
argument_list|(
literal|100
argument_list|)
expr_stmt|;
name|consumer
operator|.
name|seekToBeginning
argument_list|(
name|consumer
operator|.
name|assignment
argument_list|()
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|endpoint
operator|.
name|getConfiguration
argument_list|()
operator|.
name|getSeekTo
argument_list|()
operator|.
name|equals
argument_list|(
literal|"end"
argument_list|)
condition|)
block|{
name|log
operator|.
name|debug
argument_list|(
literal|"{} is seeking to the end on topic {}"
argument_list|,
name|threadId
argument_list|,
name|topicName
argument_list|)
expr_stmt|;
comment|// This poll to ensures we have an assigned partition otherwise seek won't work
name|consumer
operator|.
name|poll
argument_list|(
literal|100
argument_list|)
expr_stmt|;
name|consumer
operator|.
name|seekToEnd
argument_list|(
name|consumer
operator|.
name|assignment
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
while|while
condition|(
name|isRunAllowed
argument_list|()
operator|&&
operator|!
name|reConnect
operator|&&
operator|!
name|isStoppingOrStopped
argument_list|()
operator|&&
operator|!
name|isSuspendingOrSuspended
argument_list|()
condition|)
block|{
comment|// flag to break out processing on the first exception
name|boolean
name|breakOnErrorHit
init|=
literal|false
decl_stmt|;
name|log
operator|.
name|trace
argument_list|(
literal|"Polling {} from topic: {} with timeout: {}"
argument_list|,
name|threadId
argument_list|,
name|topicName
argument_list|,
name|pollTimeoutMs
argument_list|)
expr_stmt|;
name|ConsumerRecords
argument_list|<
name|Object
argument_list|,
name|Object
argument_list|>
name|allRecords
init|=
name|consumer
operator|.
name|poll
argument_list|(
name|pollTimeoutMs
argument_list|)
decl_stmt|;
for|for
control|(
name|TopicPartition
name|partition
range|:
name|allRecords
operator|.
name|partitions
argument_list|()
control|)
block|{
name|long
name|partitionLastOffset
init|=
operator|-
literal|1
decl_stmt|;
name|Iterator
argument_list|<
name|ConsumerRecord
argument_list|<
name|Object
argument_list|,
name|Object
argument_list|>
argument_list|>
name|recordIterator
init|=
name|allRecords
operator|.
name|records
argument_list|(
name|partition
argument_list|)
operator|.
name|iterator
argument_list|()
decl_stmt|;
if|if
condition|(
operator|!
name|breakOnErrorHit
operator|&&
name|recordIterator
operator|.
name|hasNext
argument_list|()
condition|)
block|{
name|ConsumerRecord
argument_list|<
name|Object
argument_list|,
name|Object
argument_list|>
name|record
decl_stmt|;
while|while
condition|(
operator|!
name|breakOnErrorHit
operator|&&
name|recordIterator
operator|.
name|hasNext
argument_list|()
condition|)
block|{
name|record
operator|=
name|recordIterator
operator|.
name|next
argument_list|()
expr_stmt|;
if|if
condition|(
name|log
operator|.
name|isTraceEnabled
argument_list|()
condition|)
block|{
name|log
operator|.
name|trace
argument_list|(
literal|"Partition = {}, offset = {}, key = {}, value = {}"
argument_list|,
name|record
operator|.
name|partition
argument_list|()
argument_list|,
name|record
operator|.
name|offset
argument_list|()
argument_list|,
name|record
operator|.
name|key
argument_list|()
argument_list|,
name|record
operator|.
name|value
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|Exchange
name|exchange
init|=
name|endpoint
operator|.
name|createKafkaExchange
argument_list|(
name|record
argument_list|)
decl_stmt|;
name|propagateHeaders
argument_list|(
name|record
argument_list|,
name|exchange
argument_list|,
name|endpoint
operator|.
name|getConfiguration
argument_list|()
argument_list|)
expr_stmt|;
comment|// if not auto commit then we have additional information on the exchange
if|if
condition|(
operator|!
name|isAutoCommitEnabled
argument_list|()
condition|)
block|{
name|exchange
operator|.
name|getIn
argument_list|()
operator|.
name|setHeader
argument_list|(
name|KafkaConstants
operator|.
name|LAST_RECORD_BEFORE_COMMIT
argument_list|,
operator|!
name|recordIterator
operator|.
name|hasNext
argument_list|()
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|endpoint
operator|.
name|getConfiguration
argument_list|()
operator|.
name|isAllowManualCommit
argument_list|()
condition|)
block|{
comment|// allow Camel users to access the Kafka consumer API to be able to do for example manual commits
name|KafkaManualCommit
name|manual
init|=
name|endpoint
operator|.
name|getComponent
argument_list|()
operator|.
name|getKafkaManualCommitFactory
argument_list|()
operator|.
name|newInstance
argument_list|(
name|exchange
argument_list|,
name|consumer
argument_list|,
name|topicName
argument_list|,
name|threadId
argument_list|,
name|offsetRepository
argument_list|,
name|partition
argument_list|,
name|record
operator|.
name|offset
argument_list|()
argument_list|)
decl_stmt|;
name|exchange
operator|.
name|getIn
argument_list|()
operator|.
name|setHeader
argument_list|(
name|KafkaConstants
operator|.
name|MANUAL_COMMIT
argument_list|,
name|manual
argument_list|)
expr_stmt|;
block|}
try|try
block|{
name|processor
operator|.
name|process
argument_list|(
name|exchange
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
name|exchange
operator|.
name|setException
argument_list|(
name|e
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|exchange
operator|.
name|getException
argument_list|()
operator|!=
literal|null
condition|)
block|{
comment|// processing failed due to an unhandled exception, what should we do
if|if
condition|(
name|endpoint
operator|.
name|getConfiguration
argument_list|()
operator|.
name|isBreakOnFirstError
argument_list|()
condition|)
block|{
comment|// we are failing and we should break out
name|log
operator|.
name|warn
argument_list|(
literal|"Error during processing {} from topic: {}. Will seek consumer to offset: {} and re-connect and start polling again."
argument_list|,
name|exchange
argument_list|,
name|topicName
argument_list|,
name|partitionLastOffset
argument_list|)
expr_stmt|;
comment|// force commit so we resume on next poll where we failed
name|commitOffset
argument_list|(
name|offsetRepository
argument_list|,
name|partition
argument_list|,
name|partitionLastOffset
argument_list|,
literal|true
argument_list|)
expr_stmt|;
comment|// continue to next partition
name|breakOnErrorHit
operator|=
literal|true
expr_stmt|;
block|}
else|else
block|{
comment|// will handle/log the exception and then continue to next
name|getExceptionHandler
argument_list|()
operator|.
name|handleException
argument_list|(
literal|"Error during processing"
argument_list|,
name|exchange
argument_list|,
name|exchange
operator|.
name|getException
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
comment|// record was success so remember its offset
name|partitionLastOffset
operator|=
name|record
operator|.
name|offset
argument_list|()
expr_stmt|;
block|}
block|}
if|if
condition|(
operator|!
name|breakOnErrorHit
condition|)
block|{
comment|// all records processed from partition so commit them
name|commitOffset
argument_list|(
name|offsetRepository
argument_list|,
name|partition
argument_list|,
name|partitionLastOffset
argument_list|,
literal|false
argument_list|)
expr_stmt|;
block|}
block|}
block|}
if|if
condition|(
name|breakOnErrorHit
condition|)
block|{
comment|// force re-connect
name|reConnect
operator|=
literal|true
expr_stmt|;
block|}
block|}
if|if
condition|(
operator|!
name|reConnect
condition|)
block|{
if|if
condition|(
name|isAutoCommitEnabled
argument_list|()
condition|)
block|{
if|if
condition|(
literal|"async"
operator|.
name|equals
argument_list|(
name|endpoint
operator|.
name|getConfiguration
argument_list|()
operator|.
name|getAutoCommitOnStop
argument_list|()
argument_list|)
condition|)
block|{
name|log
operator|.
name|info
argument_list|(
literal|"Auto commitAsync on stop {} from topic {}"
argument_list|,
name|threadId
argument_list|,
name|topicName
argument_list|)
expr_stmt|;
name|consumer
operator|.
name|commitAsync
argument_list|()
expr_stmt|;
block|}
elseif|else
if|if
condition|(
literal|"sync"
operator|.
name|equals
argument_list|(
name|endpoint
operator|.
name|getConfiguration
argument_list|()
operator|.
name|getAutoCommitOnStop
argument_list|()
argument_list|)
condition|)
block|{
name|log
operator|.
name|info
argument_list|(
literal|"Auto commitSync on stop {} from topic {}"
argument_list|,
name|threadId
argument_list|,
name|topicName
argument_list|)
expr_stmt|;
name|consumer
operator|.
name|commitSync
argument_list|()
expr_stmt|;
block|}
block|}
block|}
name|log
operator|.
name|info
argument_list|(
literal|"Unsubscribing {} from topic {}"
argument_list|,
name|threadId
argument_list|,
name|topicName
argument_list|)
expr_stmt|;
comment|// we are unsubscribing so do not re connect
name|unsubscribing
operator|=
literal|true
expr_stmt|;
name|consumer
operator|.
name|unsubscribe
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InterruptException
name|e
parameter_list|)
block|{
name|getExceptionHandler
argument_list|()
operator|.
name|handleException
argument_list|(
literal|"Interrupted while consuming "
operator|+
name|threadId
operator|+
literal|" from kafka topic"
argument_list|,
name|e
argument_list|)
expr_stmt|;
name|log
operator|.
name|info
argument_list|(
literal|"Unsubscribing {} from topic {}"
argument_list|,
name|threadId
argument_list|,
name|topicName
argument_list|)
expr_stmt|;
name|consumer
operator|.
name|unsubscribe
argument_list|()
expr_stmt|;
name|Thread
operator|.
name|currentThread
argument_list|()
operator|.
name|interrupt
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|KafkaException
name|e
parameter_list|)
block|{
comment|// some kind of error in kafka, it may happen during unsubscribing or during normal processing
if|if
condition|(
name|unsubscribing
condition|)
block|{
name|getExceptionHandler
argument_list|()
operator|.
name|handleException
argument_list|(
literal|"Error unsubscribing "
operator|+
name|threadId
operator|+
literal|" from kafka topic "
operator|+
name|topicName
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|log
operator|.
name|warn
argument_list|(
literal|"KafkaException consuming {} from topic {}. Will attempt to re-connect on next run"
argument_list|,
name|threadId
argument_list|,
name|topicName
argument_list|)
expr_stmt|;
name|reConnect
operator|=
literal|true
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
name|getExceptionHandler
argument_list|()
operator|.
name|handleException
argument_list|(
literal|"Error consuming "
operator|+
name|threadId
operator|+
literal|" from kafka topic"
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|log
operator|.
name|debug
argument_list|(
literal|"Closing {}"
argument_list|,
name|threadId
argument_list|)
expr_stmt|;
name|IOHelper
operator|.
name|close
argument_list|(
name|consumer
argument_list|)
expr_stmt|;
block|}
return|return
name|reConnect
return|;
block|}
DECL|method|commitOffset (StateRepository<String, String> offsetRepository, TopicPartition partition, long partitionLastOffset, boolean forceCommit)
specifier|private
name|void
name|commitOffset
parameter_list|(
name|StateRepository
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|offsetRepository
parameter_list|,
name|TopicPartition
name|partition
parameter_list|,
name|long
name|partitionLastOffset
parameter_list|,
name|boolean
name|forceCommit
parameter_list|)
block|{
if|if
condition|(
name|partitionLastOffset
operator|!=
operator|-
literal|1
condition|)
block|{
if|if
condition|(
operator|!
name|endpoint
operator|.
name|getConfiguration
argument_list|()
operator|.
name|isAllowManualCommit
argument_list|()
operator|&&
name|offsetRepository
operator|!=
literal|null
condition|)
block|{
name|log
operator|.
name|debug
argument_list|(
literal|"Saving offset repository state {} from topic {} with offset: {}"
argument_list|,
name|threadId
argument_list|,
name|topicName
argument_list|,
name|partitionLastOffset
argument_list|)
expr_stmt|;
name|offsetRepository
operator|.
name|setState
argument_list|(
name|serializeOffsetKey
argument_list|(
name|partition
argument_list|)
argument_list|,
name|serializeOffsetValue
argument_list|(
name|partitionLastOffset
argument_list|)
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|forceCommit
condition|)
block|{
name|log
operator|.
name|debug
argument_list|(
literal|"Forcing commitSync {} from topic {} with offset: {}"
argument_list|,
name|threadId
argument_list|,
name|topicName
argument_list|,
name|partitionLastOffset
argument_list|)
expr_stmt|;
name|consumer
operator|.
name|commitSync
argument_list|(
name|Collections
operator|.
name|singletonMap
argument_list|(
name|partition
argument_list|,
operator|new
name|OffsetAndMetadata
argument_list|(
name|partitionLastOffset
operator|+
literal|1
argument_list|)
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
block|}
DECL|method|shutdown ()
specifier|private
name|void
name|shutdown
parameter_list|()
block|{
comment|// As advised in the KAFKA-1894 ticket, calling this wakeup method breaks the infinite loop
name|consumer
operator|.
name|wakeup
argument_list|()
expr_stmt|;
block|}
annotation|@
name|Override
DECL|method|onPartitionsRevoked (Collection<TopicPartition> partitions)
specifier|public
name|void
name|onPartitionsRevoked
parameter_list|(
name|Collection
argument_list|<
name|TopicPartition
argument_list|>
name|partitions
parameter_list|)
block|{
name|log
operator|.
name|debug
argument_list|(
literal|"onPartitionsRevoked: {} from topic {}"
argument_list|,
name|threadId
argument_list|,
name|topicName
argument_list|)
expr_stmt|;
name|StateRepository
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|offsetRepository
init|=
name|endpoint
operator|.
name|getConfiguration
argument_list|()
operator|.
name|getOffsetRepository
argument_list|()
decl_stmt|;
if|if
condition|(
name|offsetRepository
operator|!=
literal|null
condition|)
block|{
for|for
control|(
name|TopicPartition
name|partition
range|:
name|partitions
control|)
block|{
name|long
name|offset
init|=
name|consumer
operator|.
name|position
argument_list|(
name|partition
argument_list|)
decl_stmt|;
name|log
operator|.
name|debug
argument_list|(
literal|"Saving offset repository state {} from topic {} with offset: {}"
argument_list|,
name|threadId
argument_list|,
name|topicName
argument_list|,
name|offset
argument_list|)
expr_stmt|;
name|offsetRepository
operator|.
name|setState
argument_list|(
name|serializeOffsetKey
argument_list|(
name|partition
argument_list|)
argument_list|,
name|serializeOffsetValue
argument_list|(
name|offset
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
block|}
annotation|@
name|Override
DECL|method|onPartitionsAssigned (Collection<TopicPartition> partitions)
specifier|public
name|void
name|onPartitionsAssigned
parameter_list|(
name|Collection
argument_list|<
name|TopicPartition
argument_list|>
name|partitions
parameter_list|)
block|{
name|log
operator|.
name|debug
argument_list|(
literal|"onPartitionsAssigned: {} from topic {}"
argument_list|,
name|threadId
argument_list|,
name|topicName
argument_list|)
expr_stmt|;
name|StateRepository
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|offsetRepository
init|=
name|endpoint
operator|.
name|getConfiguration
argument_list|()
operator|.
name|getOffsetRepository
argument_list|()
decl_stmt|;
if|if
condition|(
name|offsetRepository
operator|!=
literal|null
condition|)
block|{
for|for
control|(
name|TopicPartition
name|partition
range|:
name|partitions
control|)
block|{
name|String
name|offsetState
init|=
name|offsetRepository
operator|.
name|getState
argument_list|(
name|serializeOffsetKey
argument_list|(
name|partition
argument_list|)
argument_list|)
decl_stmt|;
if|if
condition|(
name|offsetState
operator|!=
literal|null
operator|&&
operator|!
name|offsetState
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
comment|// The state contains the last read offset so you need to seek from the next one
name|long
name|offset
init|=
name|deserializeOffsetValue
argument_list|(
name|offsetState
argument_list|)
operator|+
literal|1
decl_stmt|;
name|log
operator|.
name|debug
argument_list|(
literal|"Resuming partition {} from offset {} from state"
argument_list|,
name|partition
operator|.
name|partition
argument_list|()
argument_list|,
name|offset
argument_list|)
expr_stmt|;
name|consumer
operator|.
name|seek
argument_list|(
name|partition
argument_list|,
name|offset
argument_list|)
expr_stmt|;
block|}
block|}
block|}
block|}
block|}
DECL|method|propagateHeaders (ConsumerRecord<Object, Object> record, Exchange exchange, KafkaConfiguration kafkaConfiguration)
specifier|private
name|void
name|propagateHeaders
parameter_list|(
name|ConsumerRecord
argument_list|<
name|Object
argument_list|,
name|Object
argument_list|>
name|record
parameter_list|,
name|Exchange
name|exchange
parameter_list|,
name|KafkaConfiguration
name|kafkaConfiguration
parameter_list|)
block|{
name|HeaderFilterStrategy
name|headerFilterStrategy
init|=
name|kafkaConfiguration
operator|.
name|getHeaderFilterStrategy
argument_list|()
decl_stmt|;
name|KafkaHeaderDeserializer
name|headerDeserializer
init|=
name|kafkaConfiguration
operator|.
name|getKafkaHeaderDeserializer
argument_list|()
decl_stmt|;
name|StreamSupport
operator|.
name|stream
argument_list|(
name|record
operator|.
name|headers
argument_list|()
operator|.
name|spliterator
argument_list|()
argument_list|,
literal|false
argument_list|)
operator|.
name|filter
argument_list|(
name|header
lambda|->
name|shouldBeFiltered
argument_list|(
name|header
argument_list|,
name|exchange
argument_list|,
name|headerFilterStrategy
argument_list|)
argument_list|)
operator|.
name|forEach
argument_list|(
name|header
lambda|->
name|exchange
operator|.
name|getIn
argument_list|()
operator|.
name|setHeader
argument_list|(
name|header
operator|.
name|key
argument_list|()
argument_list|,
name|headerDeserializer
operator|.
name|deserialize
argument_list|(
name|header
operator|.
name|key
argument_list|()
argument_list|,
name|header
operator|.
name|value
argument_list|()
argument_list|)
argument_list|)
argument_list|)
expr_stmt|;
block|}
DECL|method|shouldBeFiltered (Header header, Exchange exchange, HeaderFilterStrategy headerFilterStrategy)
specifier|private
name|boolean
name|shouldBeFiltered
parameter_list|(
name|Header
name|header
parameter_list|,
name|Exchange
name|exchange
parameter_list|,
name|HeaderFilterStrategy
name|headerFilterStrategy
parameter_list|)
block|{
return|return
operator|!
name|headerFilterStrategy
operator|.
name|applyFilterToCamelHeaders
argument_list|(
name|header
operator|.
name|key
argument_list|()
argument_list|,
name|header
operator|.
name|value
argument_list|()
argument_list|,
name|exchange
argument_list|)
return|;
block|}
DECL|method|isAutoCommitEnabled ()
specifier|private
name|boolean
name|isAutoCommitEnabled
parameter_list|()
block|{
return|return
name|endpoint
operator|.
name|getConfiguration
argument_list|()
operator|.
name|isAutoCommitEnable
argument_list|()
operator|!=
literal|null
operator|&&
name|endpoint
operator|.
name|getConfiguration
argument_list|()
operator|.
name|isAutoCommitEnable
argument_list|()
return|;
block|}
DECL|method|serializeOffsetKey (TopicPartition topicPartition)
specifier|protected
name|String
name|serializeOffsetKey
parameter_list|(
name|TopicPartition
name|topicPartition
parameter_list|)
block|{
return|return
name|topicPartition
operator|.
name|topic
argument_list|()
operator|+
literal|'/'
operator|+
name|topicPartition
operator|.
name|partition
argument_list|()
return|;
block|}
DECL|method|serializeOffsetValue (long offset)
specifier|protected
name|String
name|serializeOffsetValue
parameter_list|(
name|long
name|offset
parameter_list|)
block|{
return|return
name|String
operator|.
name|valueOf
argument_list|(
name|offset
argument_list|)
return|;
block|}
DECL|method|deserializeOffsetValue (String offset)
specifier|protected
name|long
name|deserializeOffsetValue
parameter_list|(
name|String
name|offset
parameter_list|)
block|{
return|return
name|Long
operator|.
name|parseLong
argument_list|(
name|offset
argument_list|)
return|;
block|}
block|}
end_class

end_unit

